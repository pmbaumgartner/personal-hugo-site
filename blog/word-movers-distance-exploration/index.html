<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>An Exploration in Earth & Word Movers Distance | Peter Baumgartner</title><meta name=keywords content><meta name=description content="This post will be an exploration into Earth Mover&rsquo;s Distance as well as its application to NLP problems through Word Movers Distance.
To get started, we&rsquo;ll follow the benign pedagogical path of copying the Wikipedia definition:
The earth mover&rsquo;s distance (EMD) is a measure of the distance between two probability distributions over a region D. In mathematics, this is known as the Wasserstein metric. Informally, if the distributions are interpreted as two different ways of piling up a certain amount of dirt over the region D, the EMD is the minimum cost of turning one pile into the other; where the cost is assumed to be amount of dirt moved times the distance by which it is moved."><meta name=author content><link rel=canonical href=https://www.peterbaumgartner.com/blog/word-movers-distance-exploration/><link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js integrity="sha256-uVus3DnjejMqn4g7Hni+Srwf3KK8HyZB9V4809q9TWE=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://www.peterbaumgartner.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.peterbaumgartner.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.peterbaumgartner.com/favicon-32x32.png><link rel=apple-touch-icon href=https://www.peterbaumgartner.com/apple-touch-icon.png><link rel=mask-icon href=https://www.peterbaumgartner.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.104.2"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-72692144-1","auto"),ga("send","pageview"))</script><meta property="og:title" content="An Exploration in Earth & Word Movers Distance"><meta property="og:description" content="This post will be an exploration into Earth Mover&rsquo;s Distance as well as its application to NLP problems through Word Movers Distance.
To get started, we&rsquo;ll follow the benign pedagogical path of copying the Wikipedia definition:
The earth mover&rsquo;s distance (EMD) is a measure of the distance between two probability distributions over a region D. In mathematics, this is known as the Wasserstein metric. Informally, if the distributions are interpreted as two different ways of piling up a certain amount of dirt over the region D, the EMD is the minimum cost of turning one pile into the other; where the cost is assumed to be amount of dirt moved times the distance by which it is moved."><meta property="og:type" content="article"><meta property="og:url" content="https://www.peterbaumgartner.com/blog/word-movers-distance-exploration/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2017-06-18T00:00:00+00:00"><meta property="article:modified_time" content="2017-06-18T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="An Exploration in Earth & Word Movers Distance"><meta name=twitter:description content="This post will be an exploration into Earth Mover&rsquo;s Distance as well as its application to NLP problems through Word Movers Distance.
To get started, we&rsquo;ll follow the benign pedagogical path of copying the Wikipedia definition:
The earth mover&rsquo;s distance (EMD) is a measure of the distance between two probability distributions over a region D. In mathematics, this is known as the Wasserstein metric. Informally, if the distributions are interpreted as two different ways of piling up a certain amount of dirt over the region D, the EMD is the minimum cost of turning one pile into the other; where the cost is assumed to be amount of dirt moved times the distance by which it is moved."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://www.peterbaumgartner.com/blog/"},{"@type":"ListItem","position":2,"name":"An Exploration in Earth \u0026 Word Movers Distance","item":"https://www.peterbaumgartner.com/blog/word-movers-distance-exploration/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"An Exploration in Earth \u0026 Word Movers Distance","name":"An Exploration in Earth \u0026 Word Movers Distance","description":"This post will be an exploration into Earth Mover\u0026rsquo;s Distance as well as its application to NLP problems through Word Movers Distance.\nTo get started, we\u0026rsquo;ll follow the benign pedagogical path of copying the Wikipedia definition:\nThe earth mover\u0026rsquo;s distance (EMD) is a measure of the distance between two probability distributions over a region D. In mathematics, this is known as the Wasserstein metric. Informally, if the distributions are interpreted as two different ways of piling up a certain amount of dirt over the region D, the EMD is the minimum cost of turning one pile into the other; where the cost is assumed to be amount of dirt moved times the distance by which it is moved.","keywords":[],"articleBody":"This post will be an exploration into Earth Mover’s Distance as well as its application to NLP problems through Word Movers Distance.\nTo get started, we’ll follow the benign pedagogical path of copying the Wikipedia definition:\nThe earth mover’s distance (EMD) is a measure of the distance between two probability distributions over a region D. In mathematics, this is known as the Wasserstein metric. Informally, if the distributions are interpreted as two different ways of piling up a certain amount of dirt over the region D, the EMD is the minimum cost of turning one pile into the other; where the cost is assumed to be amount of dirt moved times the distance by which it is moved.\nExample (source) In the picture below, imagine the x points are piles of dirt, and y are holes. The u and w values represent the ‘mass’ (amount) of dirt in in a pile for x and negative amount needing to be filled for y points.\nWe calculate cost as the amount of dirt moved times the distance moved. If we were moving dirt from x1 to fill y1, and the distance between them is 155.7 units, the cost to fill that hole is 0.23×155.7 = 35.8.\nIt is easy to generate inefficient ways to move all the dirt – moving x2’s dirt to y1 covers a longer distance and leaves less dirt in x2 to eventually fill the remaining y holes. We want to find the most efficient way that minimizes cost. Stated formally:\nWhat is the minimum cumulative cost to fill all the holes y with dirt from x?\nThis minimum cumulative cost Earth Movers Distance. Calculating EMD boils down to a linear programming problem (a transportation problem) in order to find that cost. Several people smarter than me have figured out how to calculate this efficiently. Traditionally, Earth Movers Distance has high computational complexity: O(N3 * log N)), but some other smart people have worked hard to reduce it.\nWord Mover’s Distance Earth Movers Distance is pretty great on its own, but in 2015 Kusner et al. realized it could be applied to word embeddings (like those from word2vec) in order to calculate how semantically similar two pieces of text are. Following the idea of calculating EMD in two dimensions like we covered above, an example of comparing the distance between two sentences looks something like this:\nOutline We’re going to incrementally explore EMD/WMD through four use cases below:\nCalculating EMD for a predefined example (the pile distribution above) Calculating EMD for a random example Calculating WMD for a predefined example with a 2-dimensional projection of word vectors (to build visual intuition) Calculating WMD for a predefined example with 300-dimensional word vectors 1. Calculating EMD for a predefined example from random import randint from math import sqrt from itertools import product import os.path import matplotlib.pyplot as plt; plt.style.use('ggplot') from matplotlib.patches import Rectangle import pandas as pd import numpy as np from sklearn.metrics import euclidean_distances from pyemd import emd, emd_with_flow import gensim from MulticoreTSNE import MulticoreTSNE as TSNE %matplotlib inline In order to scaffold our understanding, we’ll create two objects to represent ideas in our problem space:\nAn individual pile of dirt, DirtPile, which has: A location in 2d space A mass (amount) of dirt An optional label A distribution of dirt piles, PileDistribution, which represents a collection “piles” or “holes”. It contains one attribute: A total mass We’re going to attempt to find the EMD from the set of piles in the image in the introduction, which is taken from an introduction to EMD you can find here. Our solution is an approximation since I’ve had to approximate the coordinate system based on the positioning.\nDefine Classes class DirtPile(): def __init__(self, position, mass, label=None): self.position = position self.x, self.y = position self.mass = mass if not label: self.label = \"{mass} @ ({x}, {y})\".format(mass=self.mass, x=self.x, y=self.y) else: self.label = label def __str__(self): return \"{mass} @ ({x}, {y})\".format(mass=self.mass, x=self.x, y=self.y) class PileDistribution(): def __init__(self, *piles): self.piles = list(piles) self.masses = {tuple(p.position): p.mass for p in self.piles} self.mass_sum = sum(p.mass for p in self.piles) def __str__(self): return '\\n'.join([str(pile) for pile in self.piles]) def __getitem__(self, index): return self.piles[index] Build Distributions x1 = DirtPile((323, 117), .74, 'x1') x2 = DirtPile((38, 342), .26, 'x2') y1 = DirtPile((323, 266), .23, 'y1') y2 = DirtPile((57, 38), .26, 'y2') y3 = DirtPile((76, 152), .51, 'y3') pd1 = PileDistribution(x1, x2) pd2 = PileDistribution(y1, y2, y3) Plot Dirt Piles def plot_dirt_piles(pd1, pd2, normed=True, r_scale=5000, figsize=(8,8), annotate=True): p1_x = [pile.x for pile in pd1.piles] p1_y = [pile.y for pile in pd1.piles] p2_x = [pile.x for pile in pd2.piles] p2_y = [pile.y for pile in pd2.piles] if normed: p1_masses = [pile.mass / pd1.mass_sum for pile in pd1.piles] p2_masses = [pile.mass / pd2.mass_sum for pile in pd2.piles] else: p2_masses = [pile.mass for pile in pd2.piles] p1_masses = [pile.mass for pile in pd1.piles] plt.figure(figsize=figsize) plt.scatter(x=p1_x, y=p1_y, s=[r_scale*m for m in p1_masses], c='r', alpha=0.5) plt.scatter(x=p2_x, y=p2_y, s=[r_scale*m for m in p2_masses], c='b', alpha=0.5) if annotate: for pile in pd1.piles: plt.annotate(xy=[pile.x, pile.y], s=pile.label, textcoords='data') for pile in pd2.piles: plt.annotate(xy=[pile.x, pile.y], s=pile.label, textcoords='data') plot_dirt_piles(pd1, pd2) Process Data for EMD Calculation We’re going to use the pyemd library. Getting the data in the correct format to calculate EMD is a bit of a chore. We need to generate what’s called a signature for each pile distribution. A signature is another way to represent data we have above. To build a signature, we need the set of all points (union) between the two distributions and the mass from each distribution for that point.\nWe’re also going to normalize the signatures so that the masses sum to 1. In this specific example they already do, but when we move on to WMD we’ll want to make sure they’re normalized.\ndef generate_signatures(piledist1, piledist2, normalize=False): # build unique list of pile positions # sorted by distance from the origin all_piles = piledist1.piles + piledist2.piles positions = sorted(list(set(pile.position for pile in all_piles)), key=lambda x: sqrt(x[0]**2 + x[1]**2)) # build signatures # check if the distribution has a mass at this position or return 0 p1_signature = [] p2_signature = [] for position in positions: p1_location_mass = piledist1.masses.get(position, 0) p2_location_mass = piledist2.masses.get(position, 0) p1_signature.append(p1_location_mass) p2_signature.append(p2_location_mass) if normalize: p1_signature = [mass / sum(p1_signature) for mass in p1_signature] p2_signature = [mass / sum(p2_signature) for mass in p2_signature] return positions, p1_signature, p2_signature positions, p1_signature, p2_signature = generate_signatures(pd1, pd2, normalize=True) print(\"Pile 1 Signature:\") for position, mass in zip(positions, p1_signature): print(\"Position:\", position, \"Mass:\", mass) print() print(\"Pile 2 Signature:\") for position, mass in zip(positions, p2_signature): print(\"Position:\", position, \"Mass:\", mass) Pile 1 Signature: Position: (57, 38) Mass: 0.0 Position: (76, 152) Mass: 0.0 Position: (323, 117) Mass: 0.74 Position: (38, 342) Mass: 0.26 Position: (323, 266) Mass: 0.0 Pile 2 Signature: Position: (57, 38) Mass: 0.26 Position: (76, 152) Mass: 0.51 Position: (323, 117) Mass: 0.0 Position: (38, 342) Mass: 0.0 Position: (323, 266) Mass: 0.23 So the signatures themselves are the mass values indexed by the unique set of locations between the two distributions.\nCalculate Distances Now that we have the set of all coordinates between the two distributions, we’re going to calculate the distance between each pair of coordinates.\ndist = euclidean_distances(positions, positions) print(pd.DataFrame(dist.round(1), index=positions, columns=positions)) (57, 38) (76, 152) (323, 117) (38, 342) (323, 266) (57, 38) 0.0 115.6 277.5 304.6 350.3 (76, 152) 115.6 0.0 249.5 193.8 272.0 (323, 117) 277.5 249.5 0.0 363.1 149.0 (38, 342) 304.6 193.8 363.1 0.0 295.0 (323, 266) 350.3 272.0 149.0 295.0 0.0 Calculate Earth Movers Distance pyemd requires that the input arrays be of type np.double, so we’re going to cast them as such. After that, we’ll just use the emd_with_flow to calculate the EMD value as well as take a look at the flow, which tells us how much earth moved where under the optimal solution.\ndef calculate_emd(signature_1, signature_2, distance_matrix): first_signature = np.array(signature_1, dtype=np.double) second_signature = np.array(signature_2, dtype=np.double) distances = np.array(distance_matrix, dtype=np.double) emd, flow = emd_with_flow(first_signature, second_signature, distances) flow = np.array(flow) return emd, flow emd, flow = calculate_emd(p1_signature, p2_signature, dist) print(\"EMD: {0:.2f}\".format(emd)) EMD: 219.16 print(\"Flow:\\n\", pd.DataFrame(flow, index=positions, columns=positions)) Flow: (57, 38) (76, 152) (323, 117) (38, 342) (323, 266) (57, 38) 0.00 0.00 0.0 0.0 0.00 (76, 152) 0.00 0.00 0.0 0.0 0.00 (323, 117) 0.26 0.25 0.0 0.0 0.23 (38, 342) 0.00 0.26 0.0 0.0 0.00 (323, 266) 0.00 0.00 0.0 0.0 0.00 Plot Solution The flow matrix is helpful in understanding the solution since we can trace how masses were moved between locations. A visualization of the piles and flow will also help illustrate this specific solution.\ndef plot_emd_solution(pd1, pd2, positions, emd, flow, normed=True, r_scale=5000, figsize=(8,8), annotate=True): p1_x = [pile.x for pile in pd1.piles] p1_y = [pile.y for pile in pd1.piles] p2_x = [pile.x for pile in pd2.piles] p2_y = [pile.y for pile in pd2.piles] if normed: p1_masses = [pile.mass / pd1.mass_sum for pile in pd1.piles] p2_masses = [pile.mass / pd2.mass_sum for pile in pd2.piles] else: p2_masses = [pile.mass for pile in pd2.piles] p1_masses = [pile.mass for pile in pd1.piles] flow_measures = [] for to_pos_ix, from_pos_ix in zip(*np.nonzero(flow)): to_pos = positions[to_pos_ix] from_pos = positions[from_pos_ix] measure = {'to' : to_pos, 'from' : from_pos, 'xs' : (to_pos[0], from_pos[0]), 'ys' : (to_pos[1], from_pos[1]), 'value' : flow[to_pos_ix, from_pos_ix]} flow_measures.append(measure) plt.figure(figsize=figsize) plt.scatter(x=p1_x, y=p1_y, s=[r_scale*m for m in p1_masses], c='r', alpha=0.8) plt.scatter(x=p2_x, y=p2_y, s=[r_scale*m for m in p2_masses], c='b', alpha=0.8) for measure in flow_measures: plt.plot([*measure['xs']], [*measure['ys']], color='black', lw=measure['value']*r_scale/100, alpha=0.7, solid_capstyle='round') (\"Example Earth Movers Distance Solution\\n EMD: {0:.2f}\".format(emd)); plot_emd_solution(pd1, pd2, positions, emd, flow) 2. Calculating EMD for a random example For fun, let’s see what a larger problem with EMD looks like. We’ll simulate two random distributions with 100 dirt piles each. Each point will be randomly placed on a 100 by 100 plane with random mass from 25 to 100.\nbig_piles1 = [DirtPile((randint(0, 100), randint(0, 100)), randint(25, 100)) for _ in range(0, 100)] big_piles2 = [DirtPile((randint(0, 100), randint(0, 100)), randint(25, 100)) for _ in range(0, 100)] big_pd1 = PileDistribution(*big_piles1) big_pd2 = PileDistribution(*big_piles2) big_positions, big_p1_signature, big_p2_signature = generate_signatures(big_pd1, big_pd2, normalize=True) big_distances = euclidean_distances(big_positions, big_positions) big_emd, big_flow = calculate_emd(big_p1_signature, big_p2_signature, big_distances) Visually Analyzing Cost It would be odd if mass had to be moved from the point (0, 0) to (100, 100), since that would mean there are no closer piles between the corners of our plane. Since the index generated for the signature is the set of positions sorted by distance from the origin, flow should occur near points next to each other in our index. This also means that the more a flow is off diagonal, the more distance will impact the total cost (at least for these simulated distributions).\nWe can visualize the cost matrix by multiplying the flow (how much mass was moved) by the distance\nbig_cost = pd.DataFrame((big_flow * big_distances), index=big_positions, columns=big_positions) plt.figure(figsize=(12,12), dpi=72) plt.pcolor(big_cost, cmap='viridis') plt.show() Most Costly Move Below we calculate which move incurred the highest cost. We’ll also point it out in our final visualization to verify.\nmost_costly_from = big_cost.max(axis=0).idxmax() most_costly_from_ix = big_positions.index(most_costly_from) most_costly_to = big_cost.max(axis=1).idxmax() most_costly_to_ix = big_positions.index(most_costly_to) most_costly_mass = big_cost.values.max().round(2) most_costly_info = (most_costly_from_ix, most_costly_from, most_costly_mass, most_costly_to_ix, most_costly_to) print(\"Most Costly Move:\") print(\"Index: [{}], Position: {} \".format(most_costly_from_ix, most_costly_from)) print(\"\\t\\t↓↓\") print(\"\\t cost: {}\".format(most_costly_mass)) print(\"\\t\\t↓↓\") print(\"Index: [{}], Position: {} \".format(most_costly_to_ix, most_costly_to)) Most Costly Move: Index: [9], Position: (14, 27) ↓↓ cost: 0.26 ↓↓ Index: [4], Position: (24, 5) Plot Solution plot_emd_solution(big_pd1, big_pd2, big_positions, big_emd, big_flow, figsize=(12, 12), r_scale=8000) # highlight most costly move plt.plot([most_costly_from[0], most_costly_to[0]], [most_costly_from[1], most_costly_to[1]], color='lime', lw=5, alpha=0.5, solid_capstyle='round'); This visualization of the solution gives us additional visual confirmation that the algorithm works. There are no piles that need to travel across the plane. Indeed, it’s possible to see clusters of flow grouped together by proximal piles. The highlighted most costly move makes sense: it’s one large pile to another over one of the longer distances between the two piles.\n3. Calculating Word Movers Distance for a predefined example with a 2-dimensional projection of word vectors We’re now going to attempt to build some intuition around what Word Movers Distance is. To start, imagine we have two sentences for which we want to calculate their similarity. Pulling from the original WMD paper, let’s use the following two sentences:\nObama speaks to the media in Illinois The President greets the press in Chicago The bolded words are the words we’ll actually use (non-stopwords). This is a great example for WMD because the sentences are about the same concept, but contain no similar words, so traditional approaches like TFIDF won’t work.\nIn EMD we calculate the cost of moving dirt between two distributions of dirt piles. In WMD, the parallel ideas to EMD are:\nPile Distribution → A Sentence / Bag of Words Dirt Pile Mass → Normalized Count of word in sentence Dirt Pile Location → A single word vector in a word embedding We have our two pile distributions (sentences) and masses (counts of words), and our locations will be provided by an existing word embedding. We’ll be using the Google News word vectors. We’re going to subset the full word embedding of 3 billion words to the 333,333 most common english words [ref].\nBuilding Intuition through Visualization The original vectors are in 300-dimensions, so we’re going to first project down to 2-dimensions using TSNE to make it easier to visualize and compare to the models we’ve built above. This will change the results for WMD, but will help with the visual comparison.\ndef read_1w_corpus(name, sep=\"\\t\"): for line in open(name): yield line.split(sep) print(\"Loading GoogleNews Vectors\") %time model = gensim.models.KeyedVectors.load_word2vec_format('/Users/pbaumgartner/data/GoogleNews-vectors-negative300.bin.gz', binary=True) vocabulary = set(model.vocab) relevant_words = [word for (word, count) in read_1w_corpus('/Users/pbaumgartner/data/count_1w.txt') if word in vocabulary] model_reduced = model[[w for w in relevant_words]] Loading GoogleNews Vectors CPU times: user 2min 15s, sys: 5.44 s, total: 2min 20s Wall time: 2min 21s The Full TSNE of the word vectors took around 22min on my computer, so I’ve saved the projection. If you run this notebook, the cell below will rebuild the projection for you.\nif not os.path.isfile('w2v_tsne.csv'): tsne = TSNE(n_components=2, n_jobs=-1, random_state=666) print(\"Performing TSNE on GoogleNews Vectors\") %time tsne_vectors = tsne.fit_transform(model_reduced.astype(np.float64)) d = pd.DataFrame(tsne_vectors, columns=['c1', 'c2']) d['word'] = relevant_words d.to_csv('w2v_tsne.csv') else: d = pd.read_csv('w2v_tsne.csv', index_col=0) Flag the embeddings that correspond to the tokens in our sentences # Obama speaks to the media in Illinois sentence1_words = ['obama', 'speaks', 'media', 'illinois'] # The President greets the press in Chicago. sentence2_words = ['president', 'greets', 'press', 'chicago'] d['sentence1'] = d['word'].isin(sentence1_words) d['sentence2'] = d['word'].isin(sentence2_words) Generate attributes for plotting def colors(row): if row['sentence1']: return '#FF0000' if row['sentence2']: return '#0000FF' else: return '#8FBC8F' def sizes(row): if row['sentence1'] or row['sentence2']: return 100 else: return 1 d['colors'] = d.apply(colors, axis=1) d['sizes'] = d.apply(sizes, axis=1) Subset the dataset to make the plotting easier d_normal = d.loc[lambda x: (x['sentence1'] == False) \u0026 (x['sentence2'] == False)] d_sentences = d.loc[lambda x: (x['sentence1'] == True) | (x['sentence2'] == True)] Calculate Axis bounds for zoomed plot xmin, xmax, ymin, ymax = (d_sentences['c1'].min()-1, d_sentences['c1'].max()+1, d_sentences['c2'].min()-1, d_sentences['c2'].max()+1) d_normal_limited = d_normal.loc[lambda x: ( (x['c1'] \u003e xmin) \u0026 (x['c1'] \u003c xmax) \u0026 (x['c2'] \u003e ymin) \u0026 (x['c2'] \u003c ymax))] Plot Sentence Word embeddings with full word embedding overlay The plot below will highlight the positions of the word embeddings from words contained in our two sentences. We’ll also overlay any additional vectors in the same location just to show the density of word vectors in this projection.\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 12)) ax1.scatter(x=d_normal['c1'], y=d_normal['c2'], c=d_normal['colors'], alpha=.5, s=d_normal['sizes'], ); ax1.scatter(x=d_sentences['c1'], y=d_sentences['c2'], c=d_sentences['colors'], alpha=1, s=d_sentences['sizes'], ); ax1.set_title('TSNE - 333,333 Most Common English Words as Vectors', fontsize=20) box = Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, fill=False, edgecolor='black') ax1.add_patch(box) ax2.scatter(x=d_normal_limited['c1'], y=d_normal_limited['c2'], c=d_normal_limited['colors'], alpha=.5, s=d_normal_limited['sizes'] + 1, ); ax2.scatter(x=d_sentences['c1'], y=d_sentences['c2'], c=d_sentences['colors'], alpha=1, s=d_sentences['sizes'] + 100, ); ax2.set_title('Enhanced Location for Relevant Words', fontsize=20) for word in d_sentences.to_dict(orient='rows'): if word['sentence2']: ax2.annotate(xy=[word['c1'], word['c2']], s=word['word'].upper(), textcoords='data', horizontalalignment='right', verticalalignment='top', bbox=dict(boxstyle=\"round\", fc=\"w\", ec=\"b\", alpha=0.7)) else: ax2.annotate(xy=[word['c1'], word['c2']] , s=word['word'].upper(), textcoords='data', horizontalalignment='left', verticalalignment='bottom', bbox=dict(boxstyle=\"round\", fc=\"w\", ec=\"r\", alpha=0.7)) fig.tight_layout() Build Components to calculate WMD sentence1_piles = [] sentence2_piles = [] for word in d_sentences.to_dict(orient='rows'): if word['sentence1']: sentence1_piles.append(DirtPile((word['c1'], word['c2']), 1, word['word'])) else: sentence2_piles.append(DirtPile((word['c1'], word['c2']), 1, word['word'])) sentence1_dist = PileDistribution(*sentence1_piles) sentence2_dist = PileDistribution(*sentence2_piles) sentence_positions, sentence_p1_signature, sentence_p2_signature = generate_signatures(sentence1_dist, sentence2_dist, normalize=True) sentence_dist = euclidean_distances(sentence_positions, sentence_positions) sentence_emd, sentence_flow = emd_with_flow(np.array(sentence_p1_signature), np.array(sentence_p2_signature), sentence_dist) plot_emd_solution(sentence1_dist, sentence2_dist, sentence_positions, sentence_emd, np.array(sentence_flow), figsize=(12, 12), r_scale=1000) plt.scatter(x=d_normal_limited['c1'], y=d_normal_limited['c2'], c=d_normal_limited['colors'], alpha=.5, s=d_normal_limited['sizes'] + 1, ); for word in d_sentences.to_dict(orient='rows'): if word['sentence2']: plt.annotate(xy=[word['c1'], word['c2']], s=word['word'].upper(), textcoords='data', horizontalalignment='right', verticalalignment='top', bbox=dict(boxstyle=\"round\", fc=\"w\", ec=\"b\", alpha=0.7)) else: plt.annotate(xy=[word['c1'], word['c2']] , s=word['word'].upper(), textcoords='data', horizontalalignment='left', verticalalignment='bottom', bbox=dict(boxstyle=\"round\", fc=\"w\", ec=\"r\", alpha=0.7)) 4. Calculating WMD for a predefined example with 300-dimensional word vectors We’re going to remove the scaffolding we used to understand EMD in two dimensions and calculate EMD using the full 300-dimensional vectors. There’s not much mechanical difference here: we still need to generate the signatures using the unique set of words between the two sentences and calculate the distances between each word in that set. However, distances are calculated over 300 dimensions rather than two.\nSince the two dimensional TSNE representation didn’t map the variables as we would expect (it missed Obama → President for example), our hypothesis is that the 300 dimensional vectors will be able to fully represent the semantics of each word and the mapping will hold. We verify below.\n# Normalize word vectors for comparison to original paper %time model.init_sims(replace=True) CPU times: user 18.5 s, sys: 2.37 s, total: 20.8 s Wall time: 20.9 s w2v_sentence1_piles, w2v_sentence2_piles = [], [] for word in sentence1_words: w2v_sentence1_piles.append({'vector' : model[word], 'mass' : 0.25, 'label' : word}) for word in sentence2_words: w2v_sentence2_piles.append({'vector' : model[word], 'mass' : 0.25, 'label' : word}) all_piles = w2v_sentence1_piles + w2v_sentence2_piles w2v_p1_signature = [0.25, 0.25, 0.25, 0.25, 0, 0, 0, 0] w2v_p2_signature = [0, 0, 0, 0, 0.25, 0.25, 0.25, 0.25] w2v_distances = euclidean_distances([i['vector'] for i in all_piles], [i['vector'] for i in all_piles]) w2v_emd, w2v_flow = calculate_emd(w2v_p1_signature, w2v_p2_signature, w2v_distances) print(\"W2V 300-Dimension EMD:\", round(w2v_emd, 2)) W2V 300-Dimension EMD: 1.02 Construct Flow Matrix to understand where masses traveled flow_df = pd.DataFrame(w2v_flow, index=[i['label'] for i in all_piles], columns=[i['label'] for i in all_piles]) flow_df obama speaks media illinois president greets press chicago obama 0.0 0.0 0.0 0.0 0.25 0.00 0.00 0.00 speaks 0.0 0.0 0.0 0.0 0.00 0.25 0.00 0.00 media 0.0 0.0 0.0 0.0 0.00 0.00 0.25 0.00 illinois 0.0 0.0 0.0 0.0 0.00 0.00 0.00 0.25 president 0.0 0.0 0.0 0.0 0.00 0.00 0.00 0.00 greets 0.0 0.0 0.0 0.0 0.00 0.00 0.00 0.00 press 0.0 0.0 0.0 0.0 0.00 0.00 0.00 0.00 chicago 0.0 0.0 0.0 0.0 0.00 0.00 0.00 0.00 Above we verify that the solution is the same as it is in the original paper, and follows our intuition about which pairs of words were most similar. The matches were:\nPresident → Obama greets → speeks press → media Chicago → Illinois Calculate Cost Matrix cost = distance × mass\n# first put distance matrix in a DF dist_df = pd.DataFrame(w2v_distances, index=[i['label'] for i in all_piles], columns=[i['label'] for i in all_piles]) cost_df = (flow_df * dist_df) cost_df obama speaks media illinois president greets press chicago obama 0.0 0.0 0.0 0.0 0.33452 0.000000 0.000000 0.000000 speaks 0.0 0.0 0.0 0.0 0.00000 0.244525 0.000000 0.000000 media 0.0 0.0 0.0 0.0 0.00000 0.000000 0.223237 0.000000 illinois 0.0 0.0 0.0 0.0 0.00000 0.000000 0.000000 0.215182 president 0.0 0.0 0.0 0.0 0.00000 0.000000 0.000000 0.000000 greets 0.0 0.0 0.0 0.0 0.00000 0.000000 0.000000 0.000000 press 0.0 0.0 0.0 0.0 0.00000 0.000000 0.000000 0.000000 chicago 0.0 0.0 0.0 0.0 0.00000 0.000000 0.000000 0.000000 Verify total cost == EMD # using np.isclose due to rounding np.isclose(w2v_emd, cost_df.values.sum()) True Summary Through this notebook we’ve gone from a basic Earth Movers Distance example in two dimensions to a full Word Movers Distance examples with the 300-dimensional word2vec vectors. Earth Movers Distance is an interesting problem on its own, and the NLP application of Word Movers Distance helps solve problems in calculating the semantic similarity of documents with no shared vocabulary.\nPython Implementations Both textacy and gensim have implementations of Word Movers Distance you can use. Gensim will require you to load (or build) a word embedding first, and I believe textacy will use the GloVe vectors from spaCy by default.\nRelated Resources WMD Tutorial Word Movers Distance in Python Slack Maestro: Helping Users Stay on Topic ","wordCount":"3335","inLanguage":"en","datePublished":"2017-06-18T00:00:00Z","dateModified":"2017-06-18T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.peterbaumgartner.com/blog/word-movers-distance-exploration/"},"publisher":{"@type":"Organization","name":"Peter Baumgartner","logo":{"@type":"ImageObject","url":"https://www.peterbaumgartner.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.peterbaumgartner.com/ accesskey=h title="Peter Baumgartner (Alt + H)">Peter Baumgartner</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://www.peterbaumgartner.com/ title=Home><span>Home</span></a></li><li><a href=https://www.peterbaumgartner.com/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://www.peterbaumgartner.com/notebooks/ title=Notebooks><span>Notebooks</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>An Exploration in Earth & Word Movers Distance</h1><div class=post-meta><span title='2017-06-18 00:00:00 +0000 UTC'>June 18, 2017</span></div></header><div class=post-content><p>This post will be an exploration into Earth Mover&rsquo;s Distance as well as its application to NLP problems through Word Movers Distance.</p><p>To get started, we&rsquo;ll follow the benign pedagogical path of copying the Wikipedia definition:</p><blockquote><p>The earth mover&rsquo;s distance (EMD) is a measure of the distance between two probability distributions over a region D. In mathematics, this is known as the Wasserstein metric. Informally, if the distributions are interpreted as two different ways of piling up a certain amount of dirt over the region D, the EMD is the minimum cost of turning one pile into the other; where the cost is assumed to be amount of dirt moved times the distance by which it is moved.</p></blockquote><h2 id=example-sourcehttproboticsstanfordeduscohenresearchemdgemdghtmlemd>Example (<a href=http://robotics.stanford.edu/~scohen/research/emdg/emdg.html#emd>source</a>)<a hidden class=anchor aria-hidden=true href=#example-sourcehttproboticsstanfordeduscohenresearchemdgemdghtmlemd>#</a></h2><p>In the picture below, imagine the <code>x</code> points are piles of dirt, and <code>y</code> are holes. The <code>u</code> and <code>w</code> values represent the &lsquo;mass&rsquo; (amount) of dirt in in a pile for <code>x</code> and negative amount needing to be filled for <code>y</code> points.</p><p><img loading=lazy src=http://robotics.stanford.edu/~scohen/research/emdg/distns.jpg alt="EMD Example"></p><p>We calculate <em>cost</em> as the amount of dirt moved times the distance moved. If we were moving dirt from <code>x1</code> to fill <code>y1</code>, and the distance between them is 155.7 units, the cost to fill that hole is <code>0.23×155.7 = 35.8</code>.</p><p>It is easy to generate inefficient ways to move all the dirt &ndash; moving <code>x2</code>&rsquo;s dirt to <code>y1</code> covers a longer distance and leaves less dirt in <code>x2</code> to eventually fill the remaining y holes. We want to find the most efficient way that minimizes cost. Stated formally:</p><blockquote><p>What is the minimum cumulative cost to fill all the holes <code>y</code> with dirt from <code>x</code>?</p></blockquote><p>This minimum cumulative cost Earth Movers Distance. Calculating EMD boils down to a linear programming problem (a <a href=http://orms.pef.czu.cz/text/transProblem.html>transportation problem</a>) in order to find that cost. Several people smarter than me have figured out how to calculate this efficiently. Traditionally, Earth Movers Distance has <a href=http://ttic.uchicago.edu/~ssameer/Research/Papers/WEMD_CVPR08.pdf>high computational complexity</a>: <code>O(N3 * log N))</code>, but some other smart people have <a href=http://www.ariel.ac.il/sites/ofirpele/fastemd/code/>worked hard to reduce it</a>.</p><h2 id=word-movers-distance>Word Mover&rsquo;s Distance<a hidden class=anchor aria-hidden=true href=#word-movers-distance>#</a></h2><p>Earth Movers Distance is pretty great on its own, but in 2015 Kusner et al. realized it could be <a href=http://proceedings.mlr.press/v37/kusnerb15.pdf>applied to word embeddings</a> (like those from word2vec) in order to calculate how semantically similar two pieces of text are. Following the idea of calculating EMD in two dimensions like we covered above, an example of comparing the distance between two sentences looks something like this:</p><p><img loading=lazy src=https://raw.githubusercontent.com/mkusner/wmd/master/fig1.png alt="word movers distance"></p><h2 id=outline>Outline<a hidden class=anchor aria-hidden=true href=#outline>#</a></h2><p>We&rsquo;re going to incrementally explore EMD/WMD through four use cases below:</p><ol><li>Calculating EMD for a predefined example (the pile distribution above)</li><li>Calculating EMD for a random example</li><li>Calculating WMD for a predefined example with a 2-dimensional projection of word vectors (to build visual intuition)</li><li>Calculating WMD for a predefined example with 300-dimensional word vectors</li></ol><h2 id=1-calculating-emd-for-a-predefined-example>1. Calculating EMD for a predefined example<a hidden class=anchor aria-hidden=true href=#1-calculating-emd-for-a-predefined-example>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> random <span style=color:#f92672>import</span> randint
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> math <span style=color:#f92672>import</span> sqrt
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> itertools <span style=color:#f92672>import</span> product
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os.path
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt; plt<span style=color:#f92672>.</span>style<span style=color:#f92672>.</span>use(<span style=color:#e6db74>&#39;ggplot&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> matplotlib.patches <span style=color:#f92672>import</span> Rectangle
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> euclidean_distances
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyemd <span style=color:#f92672>import</span> emd, emd_with_flow
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> gensim
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> MulticoreTSNE <span style=color:#f92672>import</span> MulticoreTSNE <span style=color:#66d9ef>as</span> TSNE
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>matplotlib inline
</span></span></code></pre></div><p>In order to scaffold our understanding, we&rsquo;ll create two objects to represent ideas in our problem space:</p><ul><li>An individual pile of dirt, <code>DirtPile</code>, which has:<ul><li>A location in 2d space</li><li>A mass (amount) of dirt</li><li>An optional label</li></ul></li><li>A distribution of dirt piles, <code>PileDistribution</code>, which represents a collection &ldquo;piles&rdquo; or &ldquo;holes&rdquo;. It contains one attribute:<ul><li>A total mass</li></ul></li></ul><p>We&rsquo;re going to attempt to find the EMD from the set of piles in the image in the introduction, which is taken from an introduction to EMD you can find <a href=http://robotics.stanford.edu/~scohen/research/emdg/emdg.html#emd>here</a>. Our solution is an approximation since I&rsquo;ve had to approximate the coordinate system based on the positioning.</p><h3 id=define-classes>Define Classes<a hidden class=anchor aria-hidden=true href=#define-classes>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>DirtPile</span>():
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, position, mass, label<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>position <span style=color:#f92672>=</span> position
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>x, self<span style=color:#f92672>.</span>y <span style=color:#f92672>=</span> position
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>mass <span style=color:#f92672>=</span> mass
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> label:
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>label <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{mass}</span><span style=color:#e6db74> @ (</span><span style=color:#e6db74>{x}</span><span style=color:#e6db74>, </span><span style=color:#e6db74>{y}</span><span style=color:#e6db74>)&#34;</span><span style=color:#f92672>.</span>format(mass<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>mass, x<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>x, y<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>y)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>label <span style=color:#f92672>=</span> label
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __str__(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{mass}</span><span style=color:#e6db74> @ (</span><span style=color:#e6db74>{x}</span><span style=color:#e6db74>, </span><span style=color:#e6db74>{y}</span><span style=color:#e6db74>)&#34;</span><span style=color:#f92672>.</span>format(mass<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>mass, x<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>x, y<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>y)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>PileDistribution</span>():
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, <span style=color:#f92672>*</span>piles):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>piles <span style=color:#f92672>=</span> list(piles)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>masses <span style=color:#f92672>=</span> {tuple(p<span style=color:#f92672>.</span>position): p<span style=color:#f92672>.</span>mass <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>piles}
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>mass_sum <span style=color:#f92672>=</span> sum(p<span style=color:#f92672>.</span>mass <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>piles)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __str__(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>join([str(pile) <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>piles])
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __getitem__(self, index):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>piles[index]
</span></span></code></pre></div><h3 id=build-distributions>Build Distributions<a hidden class=anchor aria-hidden=true href=#build-distributions>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>x1 <span style=color:#f92672>=</span> DirtPile((<span style=color:#ae81ff>323</span>, <span style=color:#ae81ff>117</span>), <span style=color:#ae81ff>.74</span>, <span style=color:#e6db74>&#39;x1&#39;</span>)
</span></span><span style=display:flex><span>x2 <span style=color:#f92672>=</span> DirtPile((<span style=color:#ae81ff>38</span>, <span style=color:#ae81ff>342</span>), <span style=color:#ae81ff>.26</span>, <span style=color:#e6db74>&#39;x2&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y1 <span style=color:#f92672>=</span> DirtPile((<span style=color:#ae81ff>323</span>, <span style=color:#ae81ff>266</span>), <span style=color:#ae81ff>.23</span>, <span style=color:#e6db74>&#39;y1&#39;</span>)
</span></span><span style=display:flex><span>y2 <span style=color:#f92672>=</span> DirtPile((<span style=color:#ae81ff>57</span>, <span style=color:#ae81ff>38</span>), <span style=color:#ae81ff>.26</span>, <span style=color:#e6db74>&#39;y2&#39;</span>)
</span></span><span style=display:flex><span>y3 <span style=color:#f92672>=</span> DirtPile((<span style=color:#ae81ff>76</span>, <span style=color:#ae81ff>152</span>), <span style=color:#ae81ff>.51</span>, <span style=color:#e6db74>&#39;y3&#39;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>pd1 <span style=color:#f92672>=</span> PileDistribution(x1, x2)
</span></span><span style=display:flex><span>pd2 <span style=color:#f92672>=</span> PileDistribution(y1, y2, y3)
</span></span></code></pre></div><h3 id=plot-dirt-piles>Plot Dirt Piles<a hidden class=anchor aria-hidden=true href=#plot-dirt-piles>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plot_dirt_piles</span>(pd1, pd2, normed<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, r_scale<span style=color:#f92672>=</span><span style=color:#ae81ff>5000</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>,<span style=color:#ae81ff>8</span>), annotate<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>):
</span></span><span style=display:flex><span>    p1_x <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>x <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd1<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>    p1_y <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>y <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd1<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    p2_x <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>x <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd2<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>    p2_y <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>y <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd2<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> normed:
</span></span><span style=display:flex><span>        p1_masses <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>mass <span style=color:#f92672>/</span> pd1<span style=color:#f92672>.</span>mass_sum <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd1<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>        p2_masses <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>mass <span style=color:#f92672>/</span> pd2<span style=color:#f92672>.</span>mass_sum <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd2<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        p2_masses <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>mass <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd2<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>        p1_masses <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>mass <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd1<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>figsize)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>scatter(x<span style=color:#f92672>=</span>p1_x, y<span style=color:#f92672>=</span>p1_y, s<span style=color:#f92672>=</span>[r_scale<span style=color:#f92672>*</span>m <span style=color:#66d9ef>for</span> m <span style=color:#f92672>in</span> p1_masses], c<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;r&#39;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>scatter(x<span style=color:#f92672>=</span>p2_x, y<span style=color:#f92672>=</span>p2_y, s<span style=color:#f92672>=</span>[r_scale<span style=color:#f92672>*</span>m <span style=color:#66d9ef>for</span> m <span style=color:#f92672>in</span> p2_masses], c<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;b&#39;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> annotate:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd1<span style=color:#f92672>.</span>piles:
</span></span><span style=display:flex><span>            plt<span style=color:#f92672>.</span>annotate(xy<span style=color:#f92672>=</span>[pile<span style=color:#f92672>.</span>x, pile<span style=color:#f92672>.</span>y], s<span style=color:#f92672>=</span>pile<span style=color:#f92672>.</span>label, textcoords<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;data&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd2<span style=color:#f92672>.</span>piles:
</span></span><span style=display:flex><span>            plt<span style=color:#f92672>.</span>annotate(xy<span style=color:#f92672>=</span>[pile<span style=color:#f92672>.</span>x, pile<span style=color:#f92672>.</span>y], s<span style=color:#f92672>=</span>pile<span style=color:#f92672>.</span>label, textcoords<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;data&#39;</span>)
</span></span><span style=display:flex><span>                
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>plot_dirt_piles(pd1, pd2)
</span></span></code></pre></div><p><img loading=lazy src=/images/Word%20Movers%20Distance%20Exploration_12_0.png alt=png></p><h3 id=process-data-for-emd-calculation>Process Data for EMD Calculation<a hidden class=anchor aria-hidden=true href=#process-data-for-emd-calculation>#</a></h3><p>We&rsquo;re going to use the <code>pyemd</code> library. Getting the data in the correct format to calculate EMD is a bit of a chore. We need to generate what&rsquo;s called a <code>signature</code> for each pile distribution. A signature is another way to represent data we have above. To build a signature, we need the set of all points (union) between the two distributions and the mass from each distribution for that point.</p><p>We&rsquo;re also going to normalize the signatures so that the masses sum to 1. In this specific example they already do, but when we move on to WMD we&rsquo;ll want to make sure they&rsquo;re normalized.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>generate_signatures</span>(piledist1, piledist2, normalize<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>):
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># build unique list of pile positions</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># sorted by distance from the origin</span>
</span></span><span style=display:flex><span>    all_piles <span style=color:#f92672>=</span> piledist1<span style=color:#f92672>.</span>piles <span style=color:#f92672>+</span> piledist2<span style=color:#f92672>.</span>piles
</span></span><span style=display:flex><span>    positions <span style=color:#f92672>=</span> sorted(list(set(pile<span style=color:#f92672>.</span>position <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> all_piles)),
</span></span><span style=display:flex><span>                       key<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> x: sqrt(x[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>**</span><span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> x[<span style=color:#ae81ff>1</span>]<span style=color:#f92672>**</span><span style=color:#ae81ff>2</span>))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># build signatures</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># check if the distribution has a mass at this position or return 0</span>
</span></span><span style=display:flex><span>    p1_signature <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    p2_signature <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> position <span style=color:#f92672>in</span> positions:
</span></span><span style=display:flex><span>        p1_location_mass <span style=color:#f92672>=</span> piledist1<span style=color:#f92672>.</span>masses<span style=color:#f92672>.</span>get(position, <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        p2_location_mass <span style=color:#f92672>=</span> piledist2<span style=color:#f92672>.</span>masses<span style=color:#f92672>.</span>get(position, <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        p1_signature<span style=color:#f92672>.</span>append(p1_location_mass)
</span></span><span style=display:flex><span>        p2_signature<span style=color:#f92672>.</span>append(p2_location_mass)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> normalize:
</span></span><span style=display:flex><span>        p1_signature <span style=color:#f92672>=</span> [mass <span style=color:#f92672>/</span> sum(p1_signature) <span style=color:#66d9ef>for</span> mass <span style=color:#f92672>in</span> p1_signature]
</span></span><span style=display:flex><span>        p2_signature <span style=color:#f92672>=</span> [mass <span style=color:#f92672>/</span> sum(p2_signature) <span style=color:#66d9ef>for</span> mass <span style=color:#f92672>in</span> p2_signature]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> positions, p1_signature, p2_signature
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>positions, p1_signature, p2_signature <span style=color:#f92672>=</span> generate_signatures(pd1, pd2, normalize<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Pile 1 Signature:&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> position, mass <span style=color:#f92672>in</span> zip(positions, p1_signature):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Position:&#34;</span>, position, <span style=color:#e6db74>&#34;Mass:&#34;</span>, mass)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>print()
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Pile 2 Signature:&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> position, mass <span style=color:#f92672>in</span> zip(positions, p2_signature):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Position:&#34;</span>, position, <span style=color:#e6db74>&#34;Mass:&#34;</span>, mass)
</span></span></code></pre></div><pre><code>Pile 1 Signature:
Position: (57, 38) Mass: 0.0
Position: (76, 152) Mass: 0.0
Position: (323, 117) Mass: 0.74
Position: (38, 342) Mass: 0.26
Position: (323, 266) Mass: 0.0

Pile 2 Signature:
Position: (57, 38) Mass: 0.26
Position: (76, 152) Mass: 0.51
Position: (323, 117) Mass: 0.0
Position: (38, 342) Mass: 0.0
Position: (323, 266) Mass: 0.23
</code></pre><p>So the signatures themselves are the mass values indexed by the unique set of locations between the two distributions.</p><h3 id=calculate-distances>Calculate Distances<a hidden class=anchor aria-hidden=true href=#calculate-distances>#</a></h3><p>Now that we have the set of all coordinates between the two distributions, we&rsquo;re going to calculate the distance between each pair of coordinates.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>dist <span style=color:#f92672>=</span> euclidean_distances(positions, positions)
</span></span><span style=display:flex><span>print(pd<span style=color:#f92672>.</span>DataFrame(dist<span style=color:#f92672>.</span>round(<span style=color:#ae81ff>1</span>), index<span style=color:#f92672>=</span>positions, columns<span style=color:#f92672>=</span>positions))
</span></span></code></pre></div><pre><code>            (57, 38)  (76, 152)  (323, 117)  (38, 342)  (323, 266)
(57, 38)         0.0      115.6       277.5      304.6       350.3
(76, 152)      115.6        0.0       249.5      193.8       272.0
(323, 117)     277.5      249.5         0.0      363.1       149.0
(38, 342)      304.6      193.8       363.1        0.0       295.0
(323, 266)     350.3      272.0       149.0      295.0         0.0
</code></pre><h3 id=calculate-earth-movers-distance>Calculate Earth Movers Distance<a hidden class=anchor aria-hidden=true href=#calculate-earth-movers-distance>#</a></h3><p><code>pyemd</code> requires that the input arrays be of type <code>np.double</code>, so we&rsquo;re going to cast them as such. After that, we&rsquo;ll just use the <code>emd_with_flow</code> to calculate the EMD value as well as take a look at the flow, which tells us how much earth moved where under the optimal solution.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>calculate_emd</span>(signature_1, signature_2, distance_matrix):
</span></span><span style=display:flex><span>    first_signature <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(signature_1, dtype<span style=color:#f92672>=</span>np<span style=color:#f92672>.</span>double)
</span></span><span style=display:flex><span>    second_signature <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(signature_2, dtype<span style=color:#f92672>=</span>np<span style=color:#f92672>.</span>double)
</span></span><span style=display:flex><span>    distances <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(distance_matrix, dtype<span style=color:#f92672>=</span>np<span style=color:#f92672>.</span>double)
</span></span><span style=display:flex><span>    emd, flow <span style=color:#f92672>=</span> emd_with_flow(first_signature, second_signature, distances)
</span></span><span style=display:flex><span>    flow <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(flow)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> emd, flow
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>emd, flow <span style=color:#f92672>=</span> calculate_emd(p1_signature, p2_signature, dist)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(<span style=color:#e6db74>&#34;EMD: </span><span style=color:#e6db74>{0:.2f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(emd))
</span></span></code></pre></div><pre><code>EMD: 219.16
</code></pre><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Flow:</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, pd<span style=color:#f92672>.</span>DataFrame(flow, index<span style=color:#f92672>=</span>positions, columns<span style=color:#f92672>=</span>positions))
</span></span></code></pre></div><pre><code>Flow:
             (57, 38)  (76, 152)  (323, 117)  (38, 342)  (323, 266)
(57, 38)        0.00       0.00         0.0        0.0        0.00
(76, 152)       0.00       0.00         0.0        0.0        0.00
(323, 117)      0.26       0.25         0.0        0.0        0.23
(38, 342)       0.00       0.26         0.0        0.0        0.00
(323, 266)      0.00       0.00         0.0        0.0        0.00
</code></pre><h3 id=plot-solution>Plot Solution<a hidden class=anchor aria-hidden=true href=#plot-solution>#</a></h3><p>The flow matrix is helpful in understanding the solution since we can trace how masses were moved between locations. A visualization of the piles and flow will also help illustrate this specific solution.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plot_emd_solution</span>(pd1, pd2, positions, emd, flow, normed<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, r_scale<span style=color:#f92672>=</span><span style=color:#ae81ff>5000</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>,<span style=color:#ae81ff>8</span>), annotate<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>):
</span></span><span style=display:flex><span>    p1_x <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>x <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd1<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>    p1_y <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>y <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd1<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    p2_x <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>x <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd2<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>    p2_y <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>y <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd2<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> normed:
</span></span><span style=display:flex><span>        p1_masses <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>mass <span style=color:#f92672>/</span> pd1<span style=color:#f92672>.</span>mass_sum <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd1<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>        p2_masses <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>mass <span style=color:#f92672>/</span> pd2<span style=color:#f92672>.</span>mass_sum <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd2<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        p2_masses <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>mass <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd2<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>        p1_masses <span style=color:#f92672>=</span> [pile<span style=color:#f92672>.</span>mass <span style=color:#66d9ef>for</span> pile <span style=color:#f92672>in</span> pd1<span style=color:#f92672>.</span>piles]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    flow_measures <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> to_pos_ix, from_pos_ix <span style=color:#f92672>in</span> zip(<span style=color:#f92672>*</span>np<span style=color:#f92672>.</span>nonzero(flow)):
</span></span><span style=display:flex><span>        to_pos <span style=color:#f92672>=</span> positions[to_pos_ix]
</span></span><span style=display:flex><span>        from_pos <span style=color:#f92672>=</span> positions[from_pos_ix]
</span></span><span style=display:flex><span>        measure <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;to&#39;</span> : to_pos, <span style=color:#e6db74>&#39;from&#39;</span> : from_pos,
</span></span><span style=display:flex><span>                   <span style=color:#e6db74>&#39;xs&#39;</span> : (to_pos[<span style=color:#ae81ff>0</span>], from_pos[<span style=color:#ae81ff>0</span>]),
</span></span><span style=display:flex><span>                   <span style=color:#e6db74>&#39;ys&#39;</span> : (to_pos[<span style=color:#ae81ff>1</span>], from_pos[<span style=color:#ae81ff>1</span>]),
</span></span><span style=display:flex><span>                   <span style=color:#e6db74>&#39;value&#39;</span> : flow[to_pos_ix, from_pos_ix]}
</span></span><span style=display:flex><span>        flow_measures<span style=color:#f92672>.</span>append(measure)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>figsize)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>scatter(x<span style=color:#f92672>=</span>p1_x, y<span style=color:#f92672>=</span>p1_y, s<span style=color:#f92672>=</span>[r_scale<span style=color:#f92672>*</span>m <span style=color:#66d9ef>for</span> m <span style=color:#f92672>in</span> p1_masses], c<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;r&#39;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.8</span>)   
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>scatter(x<span style=color:#f92672>=</span>p2_x, y<span style=color:#f92672>=</span>p2_y, s<span style=color:#f92672>=</span>[r_scale<span style=color:#f92672>*</span>m <span style=color:#66d9ef>for</span> m <span style=color:#f92672>in</span> p2_masses], c<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;b&#39;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.8</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> measure <span style=color:#f92672>in</span> flow_measures:
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>plot([<span style=color:#f92672>*</span>measure[<span style=color:#e6db74>&#39;xs&#39;</span>]], [<span style=color:#f92672>*</span>measure[<span style=color:#e6db74>&#39;ys&#39;</span>]],
</span></span><span style=display:flex><span>                 color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;black&#39;</span>, lw<span style=color:#f92672>=</span>measure[<span style=color:#e6db74>&#39;value&#39;</span>]<span style=color:#f92672>*</span>r_scale<span style=color:#f92672>/</span><span style=color:#ae81ff>100</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>, solid_capstyle<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;round&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#34;Example Earth Movers Distance Solution</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74> EMD: </span><span style=color:#e6db74>{0:.2f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(emd));
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>plot_emd_solution(pd1, pd2, positions, emd, flow)
</span></span></code></pre></div><p><img loading=lazy src=/images/Word%20Movers%20Distance%20Exploration_26_0.png alt=png></p><h2 id=2-calculating-emd-for-a-random-example>2. Calculating EMD for a random example<a hidden class=anchor aria-hidden=true href=#2-calculating-emd-for-a-random-example>#</a></h2><p>For fun, let&rsquo;s see what a larger problem with EMD looks like. We&rsquo;ll simulate two random distributions with 100 dirt piles each. Each point will be randomly placed on a 100 by 100 plane with random mass from 25 to 100.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>big_piles1 <span style=color:#f92672>=</span> [DirtPile((randint(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>100</span>), randint(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>100</span>)), randint(<span style=color:#ae81ff>25</span>, <span style=color:#ae81ff>100</span>)) <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>100</span>)]
</span></span><span style=display:flex><span>big_piles2 <span style=color:#f92672>=</span> [DirtPile((randint(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>100</span>), randint(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>100</span>)), randint(<span style=color:#ae81ff>25</span>, <span style=color:#ae81ff>100</span>)) <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>100</span>)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>big_pd1 <span style=color:#f92672>=</span> PileDistribution(<span style=color:#f92672>*</span>big_piles1)
</span></span><span style=display:flex><span>big_pd2 <span style=color:#f92672>=</span> PileDistribution(<span style=color:#f92672>*</span>big_piles2)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>big_positions, big_p1_signature, big_p2_signature <span style=color:#f92672>=</span> generate_signatures(big_pd1, big_pd2, normalize<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>big_distances <span style=color:#f92672>=</span> euclidean_distances(big_positions, big_positions)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>big_emd, big_flow <span style=color:#f92672>=</span> calculate_emd(big_p1_signature, big_p2_signature, big_distances)
</span></span></code></pre></div><h3 id=visually-analyzing-cost>Visually Analyzing Cost<a hidden class=anchor aria-hidden=true href=#visually-analyzing-cost>#</a></h3><p>It would be odd if mass had to be moved from the point <code>(0, 0)</code> to <code>(100, 100)</code>, since that would mean there are no closer piles between the corners of our plane. Since the index generated for the signature is the set of positions sorted by distance from the origin, flow should occur near points next to each other in our index. This also means that the more a flow is off diagonal, the more distance will impact the total cost (at least for these simulated distributions).</p><p>We can visualize the cost matrix by multiplying the flow (how much mass was moved) by the distance</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>big_cost <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame((big_flow <span style=color:#f92672>*</span> big_distances), index<span style=color:#f92672>=</span>big_positions, columns<span style=color:#f92672>=</span>big_positions)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>12</span>,<span style=color:#ae81ff>12</span>), dpi<span style=color:#f92672>=</span><span style=color:#ae81ff>72</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>pcolor(big_cost, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;viridis&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img loading=lazy src=/images/Word%20Movers%20Distance%20Exploration_33_0.png alt=png></p><h4 id=most-costly-move>Most Costly Move<a hidden class=anchor aria-hidden=true href=#most-costly-move>#</a></h4><p>Below we calculate which move incurred the highest cost. We&rsquo;ll also point it out in our final visualization to verify.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>most_costly_from <span style=color:#f92672>=</span> big_cost<span style=color:#f92672>.</span>max(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)<span style=color:#f92672>.</span>idxmax()
</span></span><span style=display:flex><span>most_costly_from_ix <span style=color:#f92672>=</span> big_positions<span style=color:#f92672>.</span>index(most_costly_from)
</span></span><span style=display:flex><span>most_costly_to <span style=color:#f92672>=</span> big_cost<span style=color:#f92672>.</span>max(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>idxmax()
</span></span><span style=display:flex><span>most_costly_to_ix <span style=color:#f92672>=</span> big_positions<span style=color:#f92672>.</span>index(most_costly_to)
</span></span><span style=display:flex><span>most_costly_mass <span style=color:#f92672>=</span> big_cost<span style=color:#f92672>.</span>values<span style=color:#f92672>.</span>max()<span style=color:#f92672>.</span>round(<span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>most_costly_info <span style=color:#f92672>=</span> (most_costly_from_ix, most_costly_from, most_costly_mass, most_costly_to_ix, most_costly_to)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Most Costly Move:&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Index: [</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>], Position: </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> &#34;</span><span style=color:#f92672>.</span>format(most_costly_from_ix, most_costly_from))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\t\t</span><span style=color:#e6db74>↓↓&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\t</span><span style=color:#e6db74>    cost: </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(most_costly_mass))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\t\t</span><span style=color:#e6db74>↓↓&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Index: [</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>], Position: </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> &#34;</span><span style=color:#f92672>.</span>format(most_costly_to_ix, most_costly_to))
</span></span></code></pre></div><pre><code>Most Costly Move:
Index: [9], Position: (14, 27) 
		↓↓
	    cost: 0.26
		↓↓
Index: [4], Position: (24, 5) 
</code></pre><h3 id=plot-solution-1>Plot Solution<a hidden class=anchor aria-hidden=true href=#plot-solution-1>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>plot_emd_solution(big_pd1, big_pd2, big_positions, big_emd, big_flow, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>12</span>), r_scale<span style=color:#f92672>=</span><span style=color:#ae81ff>8000</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># highlight most costly move</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot([most_costly_from[<span style=color:#ae81ff>0</span>], most_costly_to[<span style=color:#ae81ff>0</span>]], [most_costly_from[<span style=color:#ae81ff>1</span>], most_costly_to[<span style=color:#ae81ff>1</span>]],
</span></span><span style=display:flex><span>         color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;lime&#39;</span>, lw<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, solid_capstyle<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;round&#39;</span>);
</span></span></code></pre></div><p><img loading=lazy src=/images/Word%20Movers%20Distance%20Exploration_37_0.png alt=png></p><p>This visualization of the solution gives us additional visual confirmation that the algorithm works. There are no piles that need to travel across the plane. Indeed, it&rsquo;s possible to see clusters of flow grouped together by proximal piles. The highlighted most costly move makes sense: it&rsquo;s one large pile to another over one of the longer distances between the two piles.</p><h2 id=3-calculating-word-movers-distance-for-a-predefined-example-with-a-2-dimensional-projection-of-word-vectors>3. Calculating Word Movers Distance for a predefined example with a 2-dimensional projection of word vectors<a hidden class=anchor aria-hidden=true href=#3-calculating-word-movers-distance-for-a-predefined-example-with-a-2-dimensional-projection-of-word-vectors>#</a></h2><p>We&rsquo;re now going to attempt to build some intuition around what Word Movers Distance is. To start, imagine we have two sentences for which we want to calculate their similarity. Pulling from the original WMD paper, let&rsquo;s use the following two sentences:</p><ul><li><strong>Obama speaks</strong> to the <strong>media</strong> in <strong>Illinois</strong></li><li>The <strong>President greets</strong> the <strong>press</strong> in <strong>Chicago</strong></li></ul><p>The bolded words are the words we&rsquo;ll actually use (non-stopwords). This is a great example for WMD because the sentences are about the same concept, but contain no similar words, so traditional approaches like TFIDF won&rsquo;t work.</p><p>In EMD we calculate the cost of moving dirt between two distributions of dirt piles. In WMD, the parallel ideas to EMD are:</p><ul><li>Pile Distribution → A Sentence / Bag of Words</li><li>Dirt Pile Mass → Normalized Count of word in sentence</li><li>Dirt Pile Location → A single word vector in a word embedding</li></ul><p>We have our two pile distributions (sentences) and masses (counts of words), and our locations will be provided by an existing word embedding. We&rsquo;ll be using the Google News word vectors. We&rsquo;re going to subset the full word embedding of 3 billion words to the 333,333 most common english words [<a href=http://norvig.com/ngrams/>ref</a>].</p><h3 id=building-intuition-through-visualization>Building Intuition through Visualization<a hidden class=anchor aria-hidden=true href=#building-intuition-through-visualization>#</a></h3><p>The original vectors are in 300-dimensions, so we&rsquo;re going to first project down to 2-dimensions using TSNE to make it easier to visualize and compare to the models we&rsquo;ve built above. This will change the results for WMD, but will help with the visual comparison.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>read_1w_corpus</span>(name, sep<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\t</span><span style=color:#e6db74>&#34;</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> line <span style=color:#f92672>in</span> open(name):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>yield</span> line<span style=color:#f92672>.</span>split(sep)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Loading GoogleNews Vectors&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>time model <span style=color:#f92672>=</span> gensim<span style=color:#f92672>.</span>models<span style=color:#f92672>.</span>KeyedVectors<span style=color:#f92672>.</span>load_word2vec_format(<span style=color:#e6db74>&#39;/Users/pbaumgartner/data/GoogleNews-vectors-negative300.bin.gz&#39;</span>, binary<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>vocabulary <span style=color:#f92672>=</span> set(model<span style=color:#f92672>.</span>vocab)
</span></span><span style=display:flex><span>relevant_words <span style=color:#f92672>=</span> [word <span style=color:#66d9ef>for</span> (word, count) <span style=color:#f92672>in</span> read_1w_corpus(<span style=color:#e6db74>&#39;/Users/pbaumgartner/data/count_1w.txt&#39;</span>) <span style=color:#66d9ef>if</span> word <span style=color:#f92672>in</span> vocabulary]
</span></span><span style=display:flex><span>model_reduced <span style=color:#f92672>=</span> model[[w <span style=color:#66d9ef>for</span> w <span style=color:#f92672>in</span> relevant_words]]
</span></span></code></pre></div><pre><code>Loading GoogleNews Vectors
CPU times: user 2min 15s, sys: 5.44 s, total: 2min 20s
Wall time: 2min 21s
</code></pre><p>The Full TSNE of the word vectors took around 22min on my computer, so I&rsquo;ve saved the projection. If you run this notebook, the cell below will rebuild the projection for you.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>isfile(<span style=color:#e6db74>&#39;w2v_tsne.csv&#39;</span>):
</span></span><span style=display:flex><span>    tsne <span style=color:#f92672>=</span> TSNE(n_components<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, n_jobs<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>666</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Performing TSNE on GoogleNews Vectors&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#f92672>%</span>time tsne_vectors <span style=color:#f92672>=</span> tsne<span style=color:#f92672>.</span>fit_transform(model_reduced<span style=color:#f92672>.</span>astype(np<span style=color:#f92672>.</span>float64)) 
</span></span><span style=display:flex><span>    d <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(tsne_vectors, columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;c1&#39;</span>, <span style=color:#e6db74>&#39;c2&#39;</span>])
</span></span><span style=display:flex><span>    d[<span style=color:#e6db74>&#39;word&#39;</span>] <span style=color:#f92672>=</span> relevant_words
</span></span><span style=display:flex><span>    d<span style=color:#f92672>.</span>to_csv(<span style=color:#e6db74>&#39;w2v_tsne.csv&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>    d <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#39;w2v_tsne.csv&#39;</span>, index_col<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span></code></pre></div><h3 id=flag-the-embeddings-that-correspond-to-the-tokens-in-our-sentences>Flag the embeddings that correspond to the tokens in our sentences<a hidden class=anchor aria-hidden=true href=#flag-the-embeddings-that-correspond-to-the-tokens-in-our-sentences>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Obama speaks to the media in Illinois </span>
</span></span><span style=display:flex><span>sentence1_words <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;obama&#39;</span>, <span style=color:#e6db74>&#39;speaks&#39;</span>, <span style=color:#e6db74>&#39;media&#39;</span>, <span style=color:#e6db74>&#39;illinois&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The President greets the press in Chicago. </span>
</span></span><span style=display:flex><span>sentence2_words <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;president&#39;</span>, <span style=color:#e6db74>&#39;greets&#39;</span>, <span style=color:#e6db74>&#39;press&#39;</span>, <span style=color:#e6db74>&#39;chicago&#39;</span>]
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>d[<span style=color:#e6db74>&#39;sentence1&#39;</span>] <span style=color:#f92672>=</span> d[<span style=color:#e6db74>&#39;word&#39;</span>]<span style=color:#f92672>.</span>isin(sentence1_words)
</span></span><span style=display:flex><span>d[<span style=color:#e6db74>&#39;sentence2&#39;</span>] <span style=color:#f92672>=</span> d[<span style=color:#e6db74>&#39;word&#39;</span>]<span style=color:#f92672>.</span>isin(sentence2_words)
</span></span></code></pre></div><h3 id=generate-attributes-for-plotting>Generate attributes for plotting<a hidden class=anchor aria-hidden=true href=#generate-attributes-for-plotting>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>colors</span>(row):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> row[<span style=color:#e6db74>&#39;sentence1&#39;</span>]:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;#FF0000&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> row[<span style=color:#e6db74>&#39;sentence2&#39;</span>]:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;#0000FF&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;#8FBC8F&#39;</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>sizes</span>(row):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> row[<span style=color:#e6db74>&#39;sentence1&#39;</span>] <span style=color:#f92672>or</span> row[<span style=color:#e6db74>&#39;sentence2&#39;</span>]:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>1</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>d[<span style=color:#e6db74>&#39;colors&#39;</span>] <span style=color:#f92672>=</span> d<span style=color:#f92672>.</span>apply(colors, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>d[<span style=color:#e6db74>&#39;sizes&#39;</span>] <span style=color:#f92672>=</span> d<span style=color:#f92672>.</span>apply(sizes, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span></code></pre></div><h3 id=subset-the-dataset-to-make-the-plotting-easier>Subset the dataset to make the plotting easier<a hidden class=anchor aria-hidden=true href=#subset-the-dataset-to-make-the-plotting-easier>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>d_normal <span style=color:#f92672>=</span> d<span style=color:#f92672>.</span>loc[<span style=color:#66d9ef>lambda</span> x: (x[<span style=color:#e6db74>&#39;sentence1&#39;</span>] <span style=color:#f92672>==</span> <span style=color:#66d9ef>False</span>) <span style=color:#f92672>&amp;</span> (x[<span style=color:#e6db74>&#39;sentence2&#39;</span>] <span style=color:#f92672>==</span> <span style=color:#66d9ef>False</span>)]
</span></span><span style=display:flex><span>d_sentences <span style=color:#f92672>=</span> d<span style=color:#f92672>.</span>loc[<span style=color:#66d9ef>lambda</span> x: (x[<span style=color:#e6db74>&#39;sentence1&#39;</span>] <span style=color:#f92672>==</span> <span style=color:#66d9ef>True</span>) <span style=color:#f92672>|</span> (x[<span style=color:#e6db74>&#39;sentence2&#39;</span>] <span style=color:#f92672>==</span> <span style=color:#66d9ef>True</span>)]
</span></span></code></pre></div><h3 id=calculate-axis-bounds-for-zoomed-plot>Calculate Axis bounds for zoomed plot<a hidden class=anchor aria-hidden=true href=#calculate-axis-bounds-for-zoomed-plot>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>xmin, xmax, ymin, ymax <span style=color:#f92672>=</span> (d_sentences[<span style=color:#e6db74>&#39;c1&#39;</span>]<span style=color:#f92672>.</span>min()<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>                          d_sentences[<span style=color:#e6db74>&#39;c1&#39;</span>]<span style=color:#f92672>.</span>max()<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>                          d_sentences[<span style=color:#e6db74>&#39;c2&#39;</span>]<span style=color:#f92672>.</span>min()<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>                          d_sentences[<span style=color:#e6db74>&#39;c2&#39;</span>]<span style=color:#f92672>.</span>max()<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>d_normal_limited <span style=color:#f92672>=</span> d_normal<span style=color:#f92672>.</span>loc[<span style=color:#66d9ef>lambda</span> x: (
</span></span><span style=display:flex><span>    (x[<span style=color:#e6db74>&#39;c1&#39;</span>] <span style=color:#f92672>&gt;</span> xmin) <span style=color:#f92672>&amp;</span>
</span></span><span style=display:flex><span>    (x[<span style=color:#e6db74>&#39;c1&#39;</span>] <span style=color:#f92672>&lt;</span> xmax) <span style=color:#f92672>&amp;</span>
</span></span><span style=display:flex><span>    (x[<span style=color:#e6db74>&#39;c2&#39;</span>] <span style=color:#f92672>&gt;</span> ymin) <span style=color:#f92672>&amp;</span>
</span></span><span style=display:flex><span>    (x[<span style=color:#e6db74>&#39;c2&#39;</span>] <span style=color:#f92672>&lt;</span> ymax))]
</span></span></code></pre></div><h3 id=plot-sentence-word-embeddings-with-full-word-embedding-overlay>Plot Sentence Word embeddings with full word embedding overlay<a hidden class=anchor aria-hidden=true href=#plot-sentence-word-embeddings-with-full-word-embedding-overlay>#</a></h3><p>The plot below will highlight the positions of the word embeddings from words contained in our two sentences. We&rsquo;ll also overlay any additional vectors in the same location just to show the density of word vectors in this projection.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig, (ax1, ax2) <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>24</span>, <span style=color:#ae81ff>12</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>scatter(x<span style=color:#f92672>=</span>d_normal[<span style=color:#e6db74>&#39;c1&#39;</span>], y<span style=color:#f92672>=</span>d_normal[<span style=color:#e6db74>&#39;c2&#39;</span>], c<span style=color:#f92672>=</span>d_normal[<span style=color:#e6db74>&#39;colors&#39;</span>], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.5</span>, s<span style=color:#f92672>=</span>d_normal[<span style=color:#e6db74>&#39;sizes&#39;</span>], );
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>scatter(x<span style=color:#f92672>=</span>d_sentences[<span style=color:#e6db74>&#39;c1&#39;</span>], y<span style=color:#f92672>=</span>d_sentences[<span style=color:#e6db74>&#39;c2&#39;</span>], c<span style=color:#f92672>=</span>d_sentences[<span style=color:#e6db74>&#39;colors&#39;</span>], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, s<span style=color:#f92672>=</span>d_sentences[<span style=color:#e6db74>&#39;sizes&#39;</span>], );
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;TSNE - 333,333 Most Common English Words as Vectors&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>)
</span></span><span style=display:flex><span>box <span style=color:#f92672>=</span> Rectangle((xmin, ymin), xmax<span style=color:#f92672>-</span>xmin, ymax<span style=color:#f92672>-</span>ymin, fill<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, edgecolor<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;black&#39;</span>)
</span></span><span style=display:flex><span>ax1<span style=color:#f92672>.</span>add_patch(box)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>scatter(x<span style=color:#f92672>=</span>d_normal_limited[<span style=color:#e6db74>&#39;c1&#39;</span>], y<span style=color:#f92672>=</span>d_normal_limited[<span style=color:#e6db74>&#39;c2&#39;</span>], c<span style=color:#f92672>=</span>d_normal_limited[<span style=color:#e6db74>&#39;colors&#39;</span>], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.5</span>, s<span style=color:#f92672>=</span>d_normal_limited[<span style=color:#e6db74>&#39;sizes&#39;</span>] <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, );
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>scatter(x<span style=color:#f92672>=</span>d_sentences[<span style=color:#e6db74>&#39;c1&#39;</span>], y<span style=color:#f92672>=</span>d_sentences[<span style=color:#e6db74>&#39;c2&#39;</span>], c<span style=color:#f92672>=</span>d_sentences[<span style=color:#e6db74>&#39;colors&#39;</span>], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, s<span style=color:#f92672>=</span>d_sentences[<span style=color:#e6db74>&#39;sizes&#39;</span>] <span style=color:#f92672>+</span> <span style=color:#ae81ff>100</span>, );
</span></span><span style=display:flex><span>ax2<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;Enhanced Location for Relevant Words&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> d_sentences<span style=color:#f92672>.</span>to_dict(orient<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rows&#39;</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> word[<span style=color:#e6db74>&#39;sentence2&#39;</span>]:
</span></span><span style=display:flex><span>        ax2<span style=color:#f92672>.</span>annotate(xy<span style=color:#f92672>=</span>[word[<span style=color:#e6db74>&#39;c1&#39;</span>], word[<span style=color:#e6db74>&#39;c2&#39;</span>]],
</span></span><span style=display:flex><span>                     s<span style=color:#f92672>=</span>word[<span style=color:#e6db74>&#39;word&#39;</span>]<span style=color:#f92672>.</span>upper(),
</span></span><span style=display:flex><span>                     textcoords<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;data&#39;</span>,
</span></span><span style=display:flex><span>                     horizontalalignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;right&#39;</span>,
</span></span><span style=display:flex><span>                    verticalalignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;top&#39;</span>,
</span></span><span style=display:flex><span>                     bbox<span style=color:#f92672>=</span>dict(boxstyle<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;round&#34;</span>, fc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;w&#34;</span>, ec<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;b&#34;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        ax2<span style=color:#f92672>.</span>annotate(xy<span style=color:#f92672>=</span>[word[<span style=color:#e6db74>&#39;c1&#39;</span>], word[<span style=color:#e6db74>&#39;c2&#39;</span>]] ,
</span></span><span style=display:flex><span>                     s<span style=color:#f92672>=</span>word[<span style=color:#e6db74>&#39;word&#39;</span>]<span style=color:#f92672>.</span>upper(),
</span></span><span style=display:flex><span>                     textcoords<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;data&#39;</span>,
</span></span><span style=display:flex><span>                    horizontalalignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;left&#39;</span>,
</span></span><span style=display:flex><span>                    verticalalignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;bottom&#39;</span>,
</span></span><span style=display:flex><span>                     bbox<span style=color:#f92672>=</span>dict(boxstyle<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;round&#34;</span>, fc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;w&#34;</span>, ec<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;r&#34;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>))
</span></span><span style=display:flex><span>fig<span style=color:#f92672>.</span>tight_layout()
</span></span></code></pre></div><p><img loading=lazy src=/images/Word%20Movers%20Distance%20Exploration_57_0.png alt=png></p><h3 id=build-components-to-calculate-wmd>Build Components to calculate WMD<a hidden class=anchor aria-hidden=true href=#build-components-to-calculate-wmd>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>sentence1_piles <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>sentence2_piles <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> d_sentences<span style=color:#f92672>.</span>to_dict(orient<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rows&#39;</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> word[<span style=color:#e6db74>&#39;sentence1&#39;</span>]:
</span></span><span style=display:flex><span>        sentence1_piles<span style=color:#f92672>.</span>append(DirtPile((word[<span style=color:#e6db74>&#39;c1&#39;</span>], word[<span style=color:#e6db74>&#39;c2&#39;</span>]), <span style=color:#ae81ff>1</span>, word[<span style=color:#e6db74>&#39;word&#39;</span>]))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        sentence2_piles<span style=color:#f92672>.</span>append(DirtPile((word[<span style=color:#e6db74>&#39;c1&#39;</span>], word[<span style=color:#e6db74>&#39;c2&#39;</span>]), <span style=color:#ae81ff>1</span>, word[<span style=color:#e6db74>&#39;word&#39;</span>]))
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>sentence1_dist <span style=color:#f92672>=</span> PileDistribution(<span style=color:#f92672>*</span>sentence1_piles)
</span></span><span style=display:flex><span>sentence2_dist <span style=color:#f92672>=</span> PileDistribution(<span style=color:#f92672>*</span>sentence2_piles)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>sentence_positions, sentence_p1_signature, sentence_p2_signature <span style=color:#f92672>=</span> generate_signatures(sentence1_dist, sentence2_dist, normalize<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>sentence_dist <span style=color:#f92672>=</span> euclidean_distances(sentence_positions, sentence_positions)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sentence_emd, sentence_flow <span style=color:#f92672>=</span> emd_with_flow(np<span style=color:#f92672>.</span>array(sentence_p1_signature), np<span style=color:#f92672>.</span>array(sentence_p2_signature), sentence_dist)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>plot_emd_solution(sentence1_dist, sentence2_dist, sentence_positions, sentence_emd, np<span style=color:#f92672>.</span>array(sentence_flow), figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>12</span>), r_scale<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>scatter(x<span style=color:#f92672>=</span>d_normal_limited[<span style=color:#e6db74>&#39;c1&#39;</span>], y<span style=color:#f92672>=</span>d_normal_limited[<span style=color:#e6db74>&#39;c2&#39;</span>], c<span style=color:#f92672>=</span>d_normal_limited[<span style=color:#e6db74>&#39;colors&#39;</span>], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.5</span>, s<span style=color:#f92672>=</span>d_normal_limited[<span style=color:#e6db74>&#39;sizes&#39;</span>] <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, );
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> d_sentences<span style=color:#f92672>.</span>to_dict(orient<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rows&#39;</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> word[<span style=color:#e6db74>&#39;sentence2&#39;</span>]:
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>annotate(xy<span style=color:#f92672>=</span>[word[<span style=color:#e6db74>&#39;c1&#39;</span>], word[<span style=color:#e6db74>&#39;c2&#39;</span>]],
</span></span><span style=display:flex><span>                     s<span style=color:#f92672>=</span>word[<span style=color:#e6db74>&#39;word&#39;</span>]<span style=color:#f92672>.</span>upper(),
</span></span><span style=display:flex><span>                     textcoords<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;data&#39;</span>,
</span></span><span style=display:flex><span>                     horizontalalignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;right&#39;</span>,
</span></span><span style=display:flex><span>                    verticalalignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;top&#39;</span>,
</span></span><span style=display:flex><span>                     bbox<span style=color:#f92672>=</span>dict(boxstyle<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;round&#34;</span>, fc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;w&#34;</span>, ec<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;b&#34;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>annotate(xy<span style=color:#f92672>=</span>[word[<span style=color:#e6db74>&#39;c1&#39;</span>], word[<span style=color:#e6db74>&#39;c2&#39;</span>]] ,
</span></span><span style=display:flex><span>                     s<span style=color:#f92672>=</span>word[<span style=color:#e6db74>&#39;word&#39;</span>]<span style=color:#f92672>.</span>upper(),
</span></span><span style=display:flex><span>                     textcoords<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;data&#39;</span>,
</span></span><span style=display:flex><span>                    horizontalalignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;left&#39;</span>,
</span></span><span style=display:flex><span>                    verticalalignment<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;bottom&#39;</span>,
</span></span><span style=display:flex><span>                     bbox<span style=color:#f92672>=</span>dict(boxstyle<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;round&#34;</span>, fc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;w&#34;</span>, ec<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;r&#34;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>))
</span></span></code></pre></div><p><img loading=lazy src=/images/Word%20Movers%20Distance%20Exploration_62_0.png alt=png></p><h2 id=4-calculating-wmd-for-a-predefined-example-with-300-dimensional-word-vectors>4. Calculating WMD for a predefined example with 300-dimensional word vectors<a hidden class=anchor aria-hidden=true href=#4-calculating-wmd-for-a-predefined-example-with-300-dimensional-word-vectors>#</a></h2><p>We&rsquo;re going to remove the scaffolding we used to understand EMD in two dimensions and calculate EMD using the full 300-dimensional vectors. There&rsquo;s not much mechanical difference here: we still need to generate the signatures using the unique set of words between the two sentences and calculate the distances between each word in that set. However, distances are calculated over 300 dimensions rather than two.</p><p>Since the two dimensional TSNE representation didn&rsquo;t map the variables as we would expect (it missed Obama → President for example), our hypothesis is that the 300 dimensional vectors will be able to fully represent the semantics of each word and the mapping will hold. We verify below.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Normalize word vectors for comparison to original paper</span>
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>time model<span style=color:#f92672>.</span>init_sims(replace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><pre><code>CPU times: user 18.5 s, sys: 2.37 s, total: 20.8 s
Wall time: 20.9 s
</code></pre><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>w2v_sentence1_piles, w2v_sentence2_piles <span style=color:#f92672>=</span> [], []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> sentence1_words:
</span></span><span style=display:flex><span>    w2v_sentence1_piles<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#39;vector&#39;</span> : model[word], <span style=color:#e6db74>&#39;mass&#39;</span> : <span style=color:#ae81ff>0.25</span>, <span style=color:#e6db74>&#39;label&#39;</span> : word})
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> sentence2_words:
</span></span><span style=display:flex><span>    w2v_sentence2_piles<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#39;vector&#39;</span> : model[word], <span style=color:#e6db74>&#39;mass&#39;</span> : <span style=color:#ae81ff>0.25</span>, <span style=color:#e6db74>&#39;label&#39;</span> : word})
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>all_piles <span style=color:#f92672>=</span> w2v_sentence1_piles <span style=color:#f92672>+</span> w2v_sentence2_piles
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>w2v_p1_signature <span style=color:#f92672>=</span> [<span style=color:#ae81ff>0.25</span>, <span style=color:#ae81ff>0.25</span>, <span style=color:#ae81ff>0.25</span>, <span style=color:#ae81ff>0.25</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>w2v_p2_signature <span style=color:#f92672>=</span> [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0.25</span>, <span style=color:#ae81ff>0.25</span>, <span style=color:#ae81ff>0.25</span>, <span style=color:#ae81ff>0.25</span>]
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>w2v_distances <span style=color:#f92672>=</span> euclidean_distances([i[<span style=color:#e6db74>&#39;vector&#39;</span>] <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> all_piles], [i[<span style=color:#e6db74>&#39;vector&#39;</span>] <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> all_piles])
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>w2v_emd, w2v_flow <span style=color:#f92672>=</span> calculate_emd(w2v_p1_signature, w2v_p2_signature, w2v_distances)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(<span style=color:#e6db74>&#34;W2V 300-Dimension EMD:&#34;</span>, round(w2v_emd, <span style=color:#ae81ff>2</span>))
</span></span></code></pre></div><pre><code>W2V 300-Dimension EMD: 1.02
</code></pre><h3 id=construct-flow-matrix-to-understand-where-masses-traveled>Construct Flow Matrix to understand where masses traveled<a hidden class=anchor aria-hidden=true href=#construct-flow-matrix-to-understand-where-masses-traveled>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>flow_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(w2v_flow, index<span style=color:#f92672>=</span>[i[<span style=color:#e6db74>&#39;label&#39;</span>] <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> all_piles], columns<span style=color:#f92672>=</span>[i[<span style=color:#e6db74>&#39;label&#39;</span>] <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> all_piles])
</span></span><span style=display:flex><span>flow_df
</span></span></code></pre></div><div><table border=1 class=dataframe><thead><tr style=text-align:right><th></th><th>obama</th><th>speaks</th><th>media</th><th>illinois</th><th>president</th><th>greets</th><th>press</th><th>chicago</th></tr></thead><tbody><tr><th>obama</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.25</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><th>speaks</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00</td><td>0.25</td><td>0.00</td><td>0.00</td></tr><tr><th>media</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00</td><td>0.00</td><td>0.25</td><td>0.00</td></tr><tr><th>illinois</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.25</td></tr><tr><th>president</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><th>greets</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><th>press</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><th>chicago</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr></tbody></table></div><p>Above we verify that the solution is the same as it is in the original paper, and follows our intuition about which pairs of words were most similar. The matches were:</p><ul><li>President → Obama</li><li>greets → speeks</li><li>press → media</li><li>Chicago → Illinois</li></ul><h3 id=calculate-cost-matrix>Calculate Cost Matrix<a hidden class=anchor aria-hidden=true href=#calculate-cost-matrix>#</a></h3><p><code>cost = distance × mass</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># first put distance matrix in a DF</span>
</span></span><span style=display:flex><span>dist_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(w2v_distances, index<span style=color:#f92672>=</span>[i[<span style=color:#e6db74>&#39;label&#39;</span>] <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> all_piles], columns<span style=color:#f92672>=</span>[i[<span style=color:#e6db74>&#39;label&#39;</span>] <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> all_piles])
</span></span><span style=display:flex><span>cost_df <span style=color:#f92672>=</span> (flow_df <span style=color:#f92672>*</span> dist_df)
</span></span><span style=display:flex><span>cost_df
</span></span></code></pre></div><div><table border=1 class=dataframe><thead><tr style=text-align:right><th></th><th>obama</th><th>speaks</th><th>media</th><th>illinois</th><th>president</th><th>greets</th><th>press</th><th>chicago</th></tr></thead><tbody><tr><th>obama</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.33452</td><td>0.000000</td><td>0.000000</td><td>0.000000</td></tr><tr><th>speaks</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00000</td><td>0.244525</td><td>0.000000</td><td>0.000000</td></tr><tr><th>media</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00000</td><td>0.000000</td><td>0.223237</td><td>0.000000</td></tr><tr><th>illinois</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00000</td><td>0.000000</td><td>0.000000</td><td>0.215182</td></tr><tr><th>president</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td></tr><tr><th>greets</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td></tr><tr><th>press</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td></tr><tr><th>chicago</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.00000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td></tr></tbody></table></div><h3 id=verify-total-cost--emd>Verify total cost == EMD<a hidden class=anchor aria-hidden=true href=#verify-total-cost--emd>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># using np.isclose due to rounding</span>
</span></span><span style=display:flex><span>np<span style=color:#f92672>.</span>isclose(w2v_emd, cost_df<span style=color:#f92672>.</span>values<span style=color:#f92672>.</span>sum())
</span></span></code></pre></div><pre><code>True
</code></pre><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>Through this notebook we&rsquo;ve gone from a basic Earth Movers Distance example in two dimensions to a full Word Movers Distance examples with the 300-dimensional <code>word2vec</code> vectors. Earth Movers Distance is an interesting problem on its own, and the NLP application of Word Movers Distance helps solve problems in calculating the semantic similarity of documents with no shared vocabulary.</p><h3 id=python-implementations>Python Implementations<a hidden class=anchor aria-hidden=true href=#python-implementations>#</a></h3><p>Both <a href=http://textacy.readthedocs.io/en/latest/api_reference.html#textacy.similarity.word_movers>textacy</a> and <a href=https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.wmdistance>gensim</a> have implementations of Word Movers Distance you can use. Gensim will require you to load (or build) a word embedding first, and I believe textacy will use the GloVe vectors from spaCy by default.</p><h3 id=related-resources>Related Resources<a hidden class=anchor aria-hidden=true href=#related-resources>#</a></h3><ul><li><a href=https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html>WMD Tutorial</a></li><li><a href=http://vene.ro/blog/word-movers-distance-in-python.html>Word Movers Distance in Python</a></li><li><a href=http://blog.fastforwardlabs.com/2017/05/30/Slack-Maestro-Helping-Users-Stay-on-Topic.html>Slack Maestro: Helping Users Stay on Topic</a></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python></code></pre></div></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://www.peterbaumgartner.com/>Peter Baumgartner</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body><script data-goatcounter=https://peterbaumgartner.goatcounter.com/count async src=//gc.zgo.at/count.js></script></html>