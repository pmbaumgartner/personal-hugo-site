<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Holy NLP! Understanding Part of Speech Tags, Dependency Parsing, and Named Entity Recognition | Peter Baumgartner</title>
<meta name=keywords content>
<meta name=description content="Introduction When we think of data science, we often think of statistical analysis of numbers. But, more and more frequently, organizations generate a lot of unstructured text data that can be quantified and analyzed. A few examples are social network comments, product reviews, emails, interview transcripts.
For analyzing text, data scientists often use Natural Language Processing (NLP). In this blog post we&rsquo;ll 3 we&rsquo;ll walk through 3 common NLP tasks and look at how they can be used together to analyze text.">
<meta name=author content>
<link rel=canonical href=https://www.peterbaumgartner.com/blog/holy-nlp/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://www.peterbaumgartner.com/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://www.peterbaumgartner.com/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://www.peterbaumgartner.com/favicon-32x32.png>
<link rel=apple-touch-icon href=https://www.peterbaumgartner.com/apple-touch-icon.png>
<link rel=mask-icon href=https://www.peterbaumgartner.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.92.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-72692144-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Holy NLP! Understanding Part of Speech Tags, Dependency Parsing, and Named Entity Recognition">
<meta property="og:description" content="Introduction When we think of data science, we often think of statistical analysis of numbers. But, more and more frequently, organizations generate a lot of unstructured text data that can be quantified and analyzed. A few examples are social network comments, product reviews, emails, interview transcripts.
For analyzing text, data scientists often use Natural Language Processing (NLP). In this blog post we&rsquo;ll 3 we&rsquo;ll walk through 3 common NLP tasks and look at how they can be used together to analyze text.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://www.peterbaumgartner.com/blog/holy-nlp/"><meta property="article:section" content="blog">
<meta property="article:published_time" content="2018-05-17T19:29:07-06:00">
<meta property="article:modified_time" content="2018-05-17T19:29:07-06:00">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Holy NLP! Understanding Part of Speech Tags, Dependency Parsing, and Named Entity Recognition">
<meta name=twitter:description content="Introduction When we think of data science, we often think of statistical analysis of numbers. But, more and more frequently, organizations generate a lot of unstructured text data that can be quantified and analyzed. A few examples are social network comments, product reviews, emails, interview transcripts.
For analyzing text, data scientists often use Natural Language Processing (NLP). In this blog post we&rsquo;ll 3 we&rsquo;ll walk through 3 common NLP tasks and look at how they can be used together to analyze text.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://www.peterbaumgartner.com/blog/"},{"@type":"ListItem","position":2,"name":"Holy NLP! Understanding Part of Speech Tags, Dependency Parsing, and Named Entity Recognition","item":"https://www.peterbaumgartner.com/blog/holy-nlp/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Holy NLP! Understanding Part of Speech Tags, Dependency Parsing, and Named Entity Recognition","name":"Holy NLP! Understanding Part of Speech Tags, Dependency Parsing, and Named Entity Recognition","description":"Introduction When we think of data science, we often think of statistical analysis of numbers. But, more and more frequently, organizations generate a lot of unstructured text data that can be quantified and analyzed. A few examples are social network comments, product reviews, emails, interview transcripts.\nFor analyzing text, data scientists often use Natural Language Processing (NLP). In this blog post we\u0026rsquo;ll 3 we\u0026rsquo;ll walk through 3 common NLP tasks and look at how they can be used together to analyze text.","keywords":[],"articleBody":"Introduction When we think of data science, we often think of statistical analysis of numbers. But, more and more frequently, organizations generate a lot of unstructured text data that can be quantified and analyzed. A few examples are social network comments, product reviews, emails, interview transcripts.\nFor analyzing text, data scientists often use Natural Language Processing (NLP). In this blog post we’ll 3 we’ll walk through 3 common NLP tasks and look at how they can be used together to analyze text. The three tasks we’ll cover are:\n Part of Speech Tagging - What type of word is this? Dependency Parsing - How is this word related to other words in this sentence? Named Entity Recognition - Is this word a proper noun?  We’re going use the spaCy python library to apply these three tools together to discover who the major actors are in the Bible and what actions they take. From there, we’ll see if we can make an interesting visualization with this structured data.\nThis approach can be applied to any problem where you have a large collection of text documents and you want to understand who the major entities are, where they appear in the document, and what they’re doing. For example, DocumentCloud uses a similar approach to this with their “View Entities” analysis option.\nTokens \u0026 Part of Speech Tagging One way to extract meaning from text is to analyze individual words. The processes of breaking up a text into words is called tokenization – the resulting words are referred to as tokens. Punctuation marks are also tokens. Each token in a sentence has several attributes we can use for analysis. The part of speech of a word is one example: nouns are a person, place, or thing; verbs are actions or occurrences; adjectives are words that describe nouns. Using these attributes, it’s straightforward to create a summary of a piece of text by counting the most common nouns, verbs, and adjectives.\nUsing spaCy, we can tokenize a piece of text and access the part of speech attribute for each token. As an example application, we’ll tokenize the previous paragraph and count the most common nouns with the code below. We’ll also lemmatize the tokens, which gives the root form a word to help us standardize across forms of a word.\nfrom collections import Counter import spacy from tabulate import tabulate nlp = spacy.load('en_core_web_lg') text = \"\"\" One way to extract meaning from text is to analyze individual words. The processes of breaking up a text into words is called tokenization -- the resulting words are referred to as tokens. Punctuation marks are also tokens. Each token in a sentence has several attributes we can use for analysis. The part of speech of a word is one example: nouns are a person, place, or thing; verbs are actions or occurences; adjectives are words that describe nouns. Using these attributes, it's straightforward to create a summary of a piece of text by counting the most common nouns, verbs, and adjectives. \"\"\" doc = nlp(text) noun_counter = Counter(token.lemma_ for token in doc if token.pos_ == 'NOUN') print(tabulate(noun_counter.most_common(5), headers=['Noun', 'Count'])) Noun Count --------- ------- word 5 text 3 token 3 noun 3 attribute 2  Dependency Parsing Words also have relationships between them and there are several types of these relationships. For example, a noun can be the subject of the sentence, where it performs an action (a verb), as in “Jill laughed.” Nouns can also be the subject of the sentence, where they’re acted upon by the subject of the sentence, like John in the sentence in “Jill laughed at John.”\nDependency parsing is a way to understand these relationships between words in a sentence. While both Jill and John are nouns in the sentence “Jill laughed at John,” Jill is the subject who is doing the laughing and John is the object being laughed at. Dependency relations are a more fine-grained attribute available to understand the words through their relationships in a sentence.\nThese relationships between words can get complicated, depending on how a sentences are structured. The result of dependency parsing a sentence is a tree data structure, with the verb as the root.\nLet’s view a dependency parse of “The quick brown fox jumps over the lazy dog.”\ndoc = nlp(\"The quick brown fox jumps over the lazy dog.\") spacy.displacy.render(doc, style='dep', options={'distance' : 140}, jupyter=True) The dependency relation is also a token attribute, and spaCy has a great API for accessing different token attributes. Below we’ll print out the text of each token, its dependency relation, and the text of its parent (head) token.\ntoken_dependencies = ((token.text, token.dep_, token.head.text) for token in doc) print(tabulate(token_dependencies, headers=['Token', 'Dependency Relation', 'Parent Token'])) Token Dependency Relation Parent Token ------- --------------------- -------------- The det fox quick amod fox brown amod fox fox nsubj jumps jumps ROOT jumps over prep jumps the det dog lazy amod dog dog pobj over . punct jumps  As a lead into our analysis, we care about any tokens with an nobj relation, indicating that they’re the object in the sentence. In the example sentence, this would mean we want to capture the word “fox”.\nNamed Entity Recognition Finally there’s named entity recognition. Named Entities are the proper nouns of sentences. Computers have gotten pretty good at figuring out if they’re in a sentence and also classifying what type of entity they are.\nspaCy handles Named Entity Recognition at the document level, since the name of an entity can span several tokens. An individual token is labeled as part of an entity using an IOB scheme to flag the beginning, inside, and outside of an entity.\nIn the code below, we’ll print all the named entities at the document level using doc.ents. Then, we’ll print each token, its IOB annotation, its entity type (if it’s part of an entity).\nThe example sentence we’ll use is “Jill laughed at John Johnson.”\ndoc = nlp(\"Jill laughed at John Johnson.\") entity_types = ((ent.text, ent.label_) for ent in doc.ents) print(tabulate(entity_types, headers=['Entity', 'Entity Type'])) print() token_entity_info = ((token.text, token.ent_iob_, token.ent_type_,) for token in doc) print(tabulate(token_entity_info, headers=['Token', 'IOB Annotation', 'Entity Type'])) Entity Entity Type ------------ ------------- Jill PERSON John Johnson PERSON Token IOB Annotation Entity Type ------- ---------------- ------------- Jill B PERSON laughed O at O John B PERSON Johnson I PERSON . O  Real World Example: NLPing the Bible Each method mentioned above is pretty great on their own, but the real power of natural language processing comes when we combined these methods to extract information that follows linguistic patterns. We can use part of speech tagging, dependency parsing, and named entity recognition to understand all the actors and their actions within a large body of text. The Bible is a great example to apply these methods due to its length and broad cast of characters.\nThe data we’re importing contains one object per Bible verse. Verses are used as an reference scheme for parts of the Bible, and usually contains one or more sentences of text. We’re going to go through each verse and extract the subject, identify if it’s a person, and pull out the action that person does.\nFirst let’s load up the Bible as JSON from a GitHub repository. Then, we’ll pull out the text from each verse, send the text through spaCy to do the dependency parsing and tagging, and store the resulting documents.\nimport requests r = requests.get('https://github.com/tushortz/Bible/raw/master/json/kjv.json') bible_json = [line['fields'] for line in r.json()] print('Number of Verses:', len(bible_json)) text_generator = (line['text'] for line in bible_json) %time verse_docs = [doc for doc in nlp.pipe(text_generator, n_threads=-1)] Number of Verses: 31102 CPU times: user 4min 41s, sys: 46.6 s, total: 5min 28s Wall time: 3min 15s  We’ve parsed the text from the json into verse_docs in a little over 3 minutes, about 160 verses a second. For reference, here’s what the first 3 rows of bible_json look like:\n[{'book_id': 1, 'chapter': 1, 'comment': '', 'text': 'In the beginning God created the heaven and the earth.', 'verse': 1}, {'book_id': 1, 'chapter': 1, 'comment': '', 'text': 'And the earth was without form, and void; and darkness was upon the face of the deep. And the Spirit of God moved upon the face of the waters.', 'verse': 2}, {'book_id': 1, 'chapter': 1, 'comment': '', 'text': 'And God said, Let there be light: and there was light.', 'verse': 3}] Using Token Attributes In order to extract the actors and actions, we’re going to iterate through all of the tokens in a verse and consider 3 factors:\n Is the token the subject of the sentence (is it’s dependency relation nsubj?) Is the parent of the token a verb? (This should usually be true, but there are sometimes conflicts between the POS tagger and dependency parsing, and we’ll play it safe. Also, I’m not a linguist so there may be some other weird edge cases) Is the token a named entity that’s a person? We don’t want to extract any nouns that aren’t people. (For simplicity, we’re only going to extract first names)  If our token meets the above three conditions, we’re going to collect the following attributes:\n The text of the noun/entity Token The Span (phrase) that includes the noun and verb The verb The log probability of the verb occurring in standard English text (using log here because these probabilities are very small) The verse number  actors_and_actions = [] def token_is_subject_with_action(token): nsubj = token.dep_ == 'nsubj' head_verb = token.head.pos_ == 'VERB' person = token.ent_type_ == 'PERSON' return nsubj and head_verb and person for verse, doc in enumerate(verse_docs): for token in doc: if token_is_subject_with_action(token): span = doc[token.head.left_edge.i:token.head.right_edge.i+1] data = dict(name=token.orth_, span=span.text, verb=token.head.lower_, log_prob=token.head.prob, verse=verse) actors_and_actions.append(data) print(len(actors_and_actions)) 5878  Analysis We’ve got a list of all the actors and their actions that we’ve extracted. For a quick analysis, let’s do two things:\n Figure out the most common action (verb) for each person. Figure out the most unique action for each person. We’ll determine this as the verb that has the lowest probability of appearing in English text.  import pandas as pd action_df = pd.DataFrame(actors_and_actions) print('Unique Names:', action_df['name'].nunique()) most_common = (action_df .groupby(['name', 'verb']) .size() .groupby(level=0, group_keys=False) .nlargest(1) .rename('Count') .reset_index(level=1) .rename(columns={ 'verb': 'Most Common' }) ) # exclude log prob most_unique = (action_df[action_df['log_prob']  -20] .groupby(['name', 'verb'])['log_prob'] .min() .groupby(level=0, group_keys=False) .nsmallest(1) .rename('Log Prob.') .reset_index(level = 1) .rename(columns={ 'verb': 'Most Unique' }) ) # SO groupby credit # https: //stackoverflow.com/questions/27842613/pandas-groupby-sort-within-groups Unique Names: 534  Let’s take a look at the top 15 actors by verb counts and their most common verb.\nmost_common.sort_values('Count', ascending=False).head(15)  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Most Common Count   name       LORD said 197   Jesus said 89   David said 88   Moses said 62   Saul said 42   Ye are 34   Samuel said 28   Blessed be 24   God said 23   Solomon made 20   Joshua said 18   Peter said 18   Jacob said 17   Joseph said 17   Pharaoh said 16     Looks like a lot of people said things in the Bible, with the exception of Solomon who made a lot of things.\nAnd what were the most unique verbs, as measured by their probability of occurence? (We’ll drop duplicates here so each word is unique)\n(most_unique .drop_duplicates('Most Unique') .sort_values('Log Prob.', ascending=True) .head(15) )  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Most Unique Log Prob.   name       Abraham sojourned -19.502029   John forbad -19.497028   Saul compassed -19.282370   David tarried -19.168381   Whosoever smiteth -19.147064   Haman standeth -19.006294   Jehoahaz besought -18.932726   Benjamin ravin -18.910282   Jeroboam drave -18.904749   Julius entreated -18.723562   Joshua discomfited -18.674166   Philip findeth -18.523926   Judas surnamed -18.512678   Abram hearkened -18.380188   Samuel hewed -18.333925     Looks like we’ve got some interesting new words to learn! My favorites are discomfited and ravin.\nVisualization Let’s visualize our results next. We’re going to take the top 50 names with the most actions and plot which verse those actions occur in the whole text. We’ll also draw vertical lines where each book of the Bible starts. The names will be sorted in order of first appearance.\nThis should give us an idea at which point in the Bible each of these characters were the most active.\nWe’ll add in some separators to separate different sections of the Bible. Not being a Biblical scholar myself, I used the divisions from here, which are as follows:\nOld Testament:\n The Pentateuch, or the Books of the Law: Genesis, Exodus, Leviticus, Numbers, and Deuteronomy. Old Testament Historical Books: Joshua, Judges, Ruth, 1 Samuel, 2 Samuel, 1 Kings, 2 Kings, 1 Chronicles, 2 Chronicles, Ezra, Nehemiah, and Esther. Wisdom Literature: Job, Psalms, Proverbs, Ecclesiastes, and Song of Solomon. The Prophets: Isaiah, Jeremiah, Lamentations, Ezekiel, Daniel, Hosea, Joel, Amos, Obadiah, Jonah, Micah, Nahum, Habakkuk, Zephaniah, Haggai, Zechariah, and Malachi.  New Testament:\n The Gospels: Matthew, Mark, Luke, and John. New Testament Historical Books: Acts Epistles: Romans, 1 Corinthians, 2 Corinthians, Galatians, Ephesians, Philippians, Colossians, 1 Thessalonians, 2 Thessalonians, 1 Timothy, 2 Timothy, Titus, Philemon, Hebrews, James, 1 Peter, 2 Peter, 1 John, 2 John, 3 John, and Jude. Prophecy / Apocalyptic Literature: Revelation  In addition, we’ll separate the Old Testament from the New Testament with a red indicator line.\nimport seaborn as sns import matplotlib.pyplot as plt %matplotlib inline sns.set(context='notebook', style='dark') most_frequent_actors = list(action_df['name'].value_counts().index[:50]) top_actors_df = action_df[action_df['name'].isin(most_frequent_actors)].copy() book_locations = (pd.DataFrame(bible_json) .reset_index() .groupby('book_id')['index'] .min() .to_dict() ) fig, ax = plt.subplots(figsize=(8,12), dpi=144*2) sns.stripplot(x='verse', y='name', data=top_actors_df, ax=ax, color='xkcd:cerulean', size=3, alpha=0.25, jitter=0.25) sns.despine(bottom=True, left=True) for book, verse_num in book_locations.items(): ax.axvline(verse_num, alpha=1, lw=0.5, color='w') divisions = [1, 6, 18, 23, 40, 44, 45, 65] for div in divisions: ax.axvline(book_locations[div], alpha=0.5, lw=1.5, color='grey') ax.axvline(book_locations[40], alpha=0.5, lw=1.75, color='xkcd:coral') ax.set_xlim(left=-150) ax.set_title(\"Where Actions Occur in the Bible\\nCharacters Sorted by First Appearance\"); Visual Analysis  God is densely referred to at the beginning of the Bible, in Genesis. LORD stops being used as an entity in books of the New Testament. We can see the first time Paul is referred to in the middle of Acts. (first book after the gospels) There’s not a lot of mention of entities in the Wisdom \u0026 Poetry Sections of the Bible. Jesus' life is densely chronicled throughout the gospels. Pilate appears at the end of each of the gospels.  Issues with this Approach  Entity Recognition can’t tell the difference between two different people with the same name.  King Saul (Old Testament) Paul (The Apostle) is referred to as Saul until midway through the book of Acts   Some nouns are not actual entities. (Ye) Some nouns could use more context with full names. (Pilate)  Next Steps As always, there are ways to extend and improve this analysis. Here’s a few I’ve thought of while writing this:\n Find relationships between entities using dependency relations and understand the characters through a network analysis approach. Improve the entity extraction to capture entities beyond single names Do an analysis of non-person entities and their linguistic relations - which locations are mentioned throughout the Bible?  Wrap Up We can get pretty far doing some interesting analysis by only using token-level attributes from text! In this blog post, we covered three key NLP tools:\n Part of Speech Tagging - What type of word is this? Dependency Parsing - How is this word related to other words in this sentence? Named Entity Recognition - Is this word a proper noun?  We applied these three tools together to discover who the major actors are in the Bible and what actions they take. We plotted those actors and actions to understand where each actor had their major actions.\nThanks Thanks to Vicki Boykis and Austin Rochford for providing feedback on earlier versions of this post.\n","wordCount":"2606","inLanguage":"en","datePublished":"2018-05-17T19:29:07-06:00","dateModified":"2018-05-17T19:29:07-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.peterbaumgartner.com/blog/holy-nlp/"},"publisher":{"@type":"Organization","name":"Peter Baumgartner","logo":{"@type":"ImageObject","url":"https://www.peterbaumgartner.com/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://www.peterbaumgartner.com/ accesskey=h title="Peter Baumgartner (Alt + H)">Peter Baumgartner</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://www.peterbaumgartner.com/ title=Home>
<span>Home</span>
</a>
</li>
<li>
<a href=https://www.peterbaumgartner.com/blog/ title=Blog>
<span>Blog</span>
</a>
</li>
<li>
<a href=https://www.peterbaumgartner.com/notebooks/ title=Notebooks>
<span>Notebooks</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Holy NLP! Understanding Part of Speech Tags, Dependency Parsing, and Named Entity Recognition
</h1>
<div class=post-meta><span title="2018-05-17 19:29:07 -0600 -0600">May 17, 2018</span>
</div>
</header>
<div class=post-content><meta name=twitter:card content="summary">
<meta name=twitter:site content="@pmbaumgartner">
<meta name=twitter:creator content="@pmbaumgartner">
<meta name=twitter:title content="Holy NLP!">
<meta name=twitter:description content="How to use Part of Speech Tags, Dependency Parsing, and Named Entity Recognition to understand the characters of the Bible">
<meta name=twitter:image content="https://s31.postimg.cc/5r0stbl63/Screen_Shot_2018-05-19_at_1.15.32_PM.png">
<h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2>
<p>When we think of data science, we often think of statistical analysis of numbers. But, more and more frequently, organizations generate a lot of unstructured text data that can be quantified and analyzed. A few examples are social network comments, product reviews, emails, interview transcripts.</p>
<p>For analyzing text, data scientists often use Natural Language Processing (NLP). In this blog post we&rsquo;ll 3 we&rsquo;ll walk through 3 common NLP tasks and look at how they can be used together to analyze text. The three tasks we&rsquo;ll cover are:</p>
<ol>
<li><strong>Part of Speech Tagging</strong> - What type of word is this?</li>
<li><strong>Dependency Parsing</strong> - How is this word related to other words in this sentence?</li>
<li><strong>Named Entity Recognition</strong> - Is this word a proper noun?</li>
</ol>
<p>We&rsquo;re going use the <code>spaCy</code> python library to apply these three tools together to discover who the major actors are in the Bible and what actions they take. From there, we&rsquo;ll see if we can make an interesting visualization with this structured data.</p>
<p>This approach can be applied to any problem where you have a large collection of text documents and you want to understand who the major entities are, where they appear in the document, and what they&rsquo;re doing. For example, DocumentCloud uses a <a href=https://www.documentcloud.org/public/search/>similar approach</a> to this with their &ldquo;View Entities&rdquo; analysis option.</p>
<h3 id=tokens--part-of-speech-tagging>Tokens & Part of Speech Tagging<a hidden class=anchor aria-hidden=true href=#tokens--part-of-speech-tagging>#</a></h3>
<p>One way to extract meaning from text is to analyze individual words. The processes of breaking up a text into words is called tokenization &ndash; the resulting words are referred to as tokens. Punctuation marks are also tokens. Each token in a sentence has several attributes we can use for analysis. The part of speech of a word is one example: nouns are a person, place, or thing; verbs are actions or occurrences; adjectives are words that describe nouns. Using these attributes, it&rsquo;s straightforward to create a summary of a piece of text by counting the most common nouns, verbs, and adjectives.</p>
<p>Using <code>spaCy</code>, we can tokenize a piece of text and access the part of speech attribute for each token. As an example application, we&rsquo;ll tokenize the previous paragraph and count the most common nouns with the code below. We&rsquo;ll also lemmatize the tokens, which gives the root form a word to help us standardize across forms of a word.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> Counter
<span style=color:#f92672>import</span> spacy
<span style=color:#f92672>from</span> tabulate <span style=color:#f92672>import</span> tabulate
nlp <span style=color:#f92672>=</span> spacy<span style=color:#f92672>.</span>load(<span style=color:#e6db74>&#39;en_core_web_lg&#39;</span>)

text <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>One way to extract meaning from text is to analyze individual words.
</span><span style=color:#e6db74>The processes of breaking up a text into words is called tokenization --
</span><span style=color:#e6db74>the resulting words are referred to as tokens.
</span><span style=color:#e6db74>Punctuation marks are also tokens.
</span><span style=color:#e6db74>Each token in a sentence has several attributes we can use for analysis.
</span><span style=color:#e6db74>The part of speech of a word is one example: nouns are a person, place, or thing;
</span><span style=color:#e6db74>verbs are actions or occurences; adjectives are words that describe nouns. 
</span><span style=color:#e6db74>Using these attributes, it&#39;s straightforward to create a summary of a piece of text
</span><span style=color:#e6db74>by counting the most common nouns, verbs, and adjectives. 
</span><span style=color:#e6db74>&#34;&#34;&#34;</span>

doc <span style=color:#f92672>=</span> nlp(text)
noun_counter <span style=color:#f92672>=</span> Counter(token<span style=color:#f92672>.</span>lemma_ <span style=color:#66d9ef>for</span> token <span style=color:#f92672>in</span> doc <span style=color:#66d9ef>if</span> token<span style=color:#f92672>.</span>pos_ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;NOUN&#39;</span>)

print(tabulate(noun_counter<span style=color:#f92672>.</span>most_common(<span style=color:#ae81ff>5</span>), headers<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;Noun&#39;</span>, <span style=color:#e6db74>&#39;Count&#39;</span>]))
</code></pre></div><pre><code>Noun         Count
---------  -------
word             5
text             3
token            3
noun             3
attribute        2
</code></pre>
<h3 id=dependency-parsing>Dependency Parsing<a hidden class=anchor aria-hidden=true href=#dependency-parsing>#</a></h3>
<p>Words also have relationships between them and there are several types of these relationships. For example, a noun can be the subject of the sentence, where it performs an action (a verb), as in &ldquo;Jill laughed.&rdquo; Nouns can also be the subject of the sentence, where they&rsquo;re acted upon by the subject of the sentence, like John in the sentence in &ldquo;Jill laughed at John.&rdquo;</p>
<p>Dependency parsing is a way to understand these relationships between words in a sentence. While both Jill and John are nouns in the sentence &ldquo;Jill laughed at John,&rdquo; Jill is the subject who is doing the laughing and John is the object being laughed at. Dependency relations are a more fine-grained attribute available to understand the words through their relationships in a sentence.</p>
<p>These relationships between words can get complicated, depending on how a sentences are structured. The result of dependency parsing a sentence is a tree data structure, with the verb as the root.</p>
<p>Let&rsquo;s view a dependency parse of &ldquo;The quick brown fox jumps over the lazy dog.&rdquo;</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>doc <span style=color:#f92672>=</span> nlp(<span style=color:#e6db74>&#34;The quick brown fox jumps over the lazy dog.&#34;</span>)
spacy<span style=color:#f92672>.</span>displacy<span style=color:#f92672>.</span>render(doc, style<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;dep&#39;</span>, options<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;distance&#39;</span> : <span style=color:#ae81ff>140</span>}, jupyter<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</code></pre></div><p><img loading=lazy src=/images/fox-parse.svg alt=fox-parse>
</p>
<p>The dependency relation is also a token attribute, and <code>spaCy</code> has a <a href=https://spacy.io/api/token>great API</a> for accessing different token attributes. Below we&rsquo;ll print out the text of each token, its dependency relation, and the text of its parent (head) token.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>token_dependencies <span style=color:#f92672>=</span> ((token<span style=color:#f92672>.</span>text, token<span style=color:#f92672>.</span>dep_, token<span style=color:#f92672>.</span>head<span style=color:#f92672>.</span>text) <span style=color:#66d9ef>for</span> token <span style=color:#f92672>in</span> doc)

print(tabulate(token_dependencies, headers<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;Token&#39;</span>, <span style=color:#e6db74>&#39;Dependency Relation&#39;</span>, <span style=color:#e6db74>&#39;Parent Token&#39;</span>]))
</code></pre></div><pre><code>Token    Dependency Relation    Parent Token
-------  ---------------------  --------------
The      det                    fox
quick    amod                   fox
brown    amod                   fox
fox      nsubj                  jumps
jumps    ROOT                   jumps
over     prep                   jumps
the      det                    dog
lazy     amod                   dog
dog      pobj                   over
.        punct                  jumps
</code></pre>
<p>As a lead into our analysis, we care about any tokens with an <code>nobj</code> relation, indicating that they&rsquo;re the object in the sentence. In the example sentence, this would mean we want to capture the word &ldquo;fox&rdquo;.</p>
<h3 id=named-entity-recognition>Named Entity Recognition<a hidden class=anchor aria-hidden=true href=#named-entity-recognition>#</a></h3>
<p>Finally there&rsquo;s named entity recognition. Named Entities are the proper nouns of sentences. Computers have gotten pretty good at figuring out if they&rsquo;re in a sentence and also classifying what type of entity they are.</p>
<p><code>spaCy</code> handles Named Entity Recognition at the document level, since the name of an entity can span several tokens. An individual token is labeled as part of an entity using an <a href=https://spacy.io/usage/linguistic-features#section-named-entities>IOB scheme</a> to flag the beginning, inside, and outside of an entity.</p>
<p>In the code below, we&rsquo;ll print all the named entities at the document level using <code>doc.ents</code>. Then, we&rsquo;ll print each token, its IOB annotation, its entity type (if it&rsquo;s part of an entity).</p>
<p>The example sentence we&rsquo;ll use is &ldquo;Jill laughed at John Johnson.&rdquo;</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>doc <span style=color:#f92672>=</span> nlp(<span style=color:#e6db74>&#34;Jill laughed at John Johnson.&#34;</span>)

entity_types <span style=color:#f92672>=</span> ((ent<span style=color:#f92672>.</span>text, ent<span style=color:#f92672>.</span>label_) <span style=color:#66d9ef>for</span> ent <span style=color:#f92672>in</span> doc<span style=color:#f92672>.</span>ents)
print(tabulate(entity_types, headers<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;Entity&#39;</span>, <span style=color:#e6db74>&#39;Entity Type&#39;</span>]))
print()
token_entity_info <span style=color:#f92672>=</span> ((token<span style=color:#f92672>.</span>text, token<span style=color:#f92672>.</span>ent_iob_, token<span style=color:#f92672>.</span>ent_type_,) <span style=color:#66d9ef>for</span> token <span style=color:#f92672>in</span> doc)
print(tabulate(token_entity_info, headers<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;Token&#39;</span>, <span style=color:#e6db74>&#39;IOB Annotation&#39;</span>, <span style=color:#e6db74>&#39;Entity Type&#39;</span>]))
</code></pre></div><pre><code>Entity        Entity Type
------------  -------------
Jill          PERSON
John Johnson  PERSON

Token    IOB Annotation    Entity Type
-------  ----------------  -------------
Jill     B                 PERSON
laughed  O
at       O
John     B                 PERSON
Johnson  I                 PERSON
.        O
</code></pre>
<h2 id=real-world-example-nlping-the-bible>Real World Example: NLPing the Bible<a hidden class=anchor aria-hidden=true href=#real-world-example-nlping-the-bible>#</a></h2>
<p>Each method mentioned above is pretty great on their own, but the real power of natural language processing comes when we combined these methods to extract information that follows linguistic patterns. We can use part of speech tagging, dependency parsing, and named entity recognition to understand all the actors and their actions within a large body of text. The Bible is a great example to apply these methods due to its length and broad cast of characters.</p>
<p>The data we&rsquo;re importing contains one object per Bible verse. Verses are used as an reference scheme for parts of the Bible, and usually contains one or more sentences of text. We&rsquo;re going to go through each verse and extract the subject, identify if it&rsquo;s a person, and pull out the action that person does.</p>
<p>First let&rsquo;s load up the Bible as JSON from a GitHub repository. Then, we&rsquo;ll pull out the text from each verse, send the text through spaCy to do the dependency parsing and tagging, and store the resulting documents.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> requests

r <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;https://github.com/tushortz/Bible/raw/master/json/kjv.json&#39;</span>)
bible_json <span style=color:#f92672>=</span> [line[<span style=color:#e6db74>&#39;fields&#39;</span>] <span style=color:#66d9ef>for</span> line <span style=color:#f92672>in</span> r<span style=color:#f92672>.</span>json()]
print(<span style=color:#e6db74>&#39;Number of Verses:&#39;</span>, len(bible_json))

text_generator <span style=color:#f92672>=</span> (line[<span style=color:#e6db74>&#39;text&#39;</span>] <span style=color:#66d9ef>for</span> line <span style=color:#f92672>in</span> bible_json)

<span style=color:#f92672>%</span>time verse_docs <span style=color:#f92672>=</span> [doc <span style=color:#66d9ef>for</span> doc <span style=color:#f92672>in</span> nlp<span style=color:#f92672>.</span>pipe(text_generator, n_threads<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)]
</code></pre></div><pre><code>Number of Verses: 31102
CPU times: user 4min 41s, sys: 46.6 s, total: 5min 28s
Wall time: 3min 15s
</code></pre>
<p>We&rsquo;ve parsed the text from the json into <code>verse_docs</code> in a little over 3 minutes, about 160 verses a second. For reference, here&rsquo;s what the first 3 rows of <code>bible_json</code> look like:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript>[{<span style=color:#e6db74>&#39;book_id&#39;</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>1</span>,
  <span style=color:#e6db74>&#39;chapter&#39;</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>1</span>,
  <span style=color:#e6db74>&#39;comment&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;&#39;</span>,
  <span style=color:#e6db74>&#39;text&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;In the beginning God created the heaven and the earth.&#39;</span>,
  <span style=color:#e6db74>&#39;verse&#39;</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>1</span>},
 {<span style=color:#e6db74>&#39;book_id&#39;</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>1</span>,
  <span style=color:#e6db74>&#39;chapter&#39;</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>1</span>,
  <span style=color:#e6db74>&#39;comment&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;&#39;</span>,
  <span style=color:#e6db74>&#39;text&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;And the earth was without form, and void; and darkness was upon the face of the deep. And the Spirit of God moved upon the face of the waters.&#39;</span>,
  <span style=color:#e6db74>&#39;verse&#39;</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>2</span>},
 {<span style=color:#e6db74>&#39;book_id&#39;</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>1</span>,
  <span style=color:#e6db74>&#39;chapter&#39;</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>1</span>,
  <span style=color:#e6db74>&#39;comment&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;&#39;</span>,
  <span style=color:#e6db74>&#39;text&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;And God said, Let there be light: and there was light.&#39;</span>,
  <span style=color:#e6db74>&#39;verse&#39;</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>3</span>}]
</code></pre></div><h3 id=using-token-attributes>Using Token Attributes<a hidden class=anchor aria-hidden=true href=#using-token-attributes>#</a></h3>
<p>In order to extract the actors and actions, we&rsquo;re going to iterate through all of the tokens in a verse and consider 3 factors:</p>
<ol>
<li>Is the token the subject of the sentence (is it&rsquo;s dependency relation <code>nsubj</code>?)</li>
<li>Is the parent of the token a verb? (This should usually be true, but there are sometimes conflicts between the POS tagger and dependency parsing, and we&rsquo;ll play it safe. Also, I&rsquo;m not a linguist so there may be some other weird edge cases)</li>
<li>Is the token a named entity that&rsquo;s a person? We don&rsquo;t want to extract any nouns that aren&rsquo;t people. (For simplicity, we&rsquo;re only going to extract first names)</li>
</ol>
<p>If our token meets the above three conditions, we&rsquo;re going to collect the following attributes:</p>
<ol>
<li>The text of the noun/entity Token</li>
<li>The Span (phrase) that includes the noun and verb</li>
<li>The verb</li>
<li>The log probability of the verb occurring in standard English text (using log here because these probabilities are very small)</li>
<li>The verse number</li>
</ol>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>actors_and_actions <span style=color:#f92672>=</span> []

<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>token_is_subject_with_action</span>(token):
    nsubj <span style=color:#f92672>=</span> token<span style=color:#f92672>.</span>dep_ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;nsubj&#39;</span>
    head_verb <span style=color:#f92672>=</span> token<span style=color:#f92672>.</span>head<span style=color:#f92672>.</span>pos_ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;VERB&#39;</span>
    person <span style=color:#f92672>=</span> token<span style=color:#f92672>.</span>ent_type_ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;PERSON&#39;</span>
    <span style=color:#66d9ef>return</span> nsubj <span style=color:#f92672>and</span> head_verb <span style=color:#f92672>and</span> person

<span style=color:#66d9ef>for</span> verse, doc <span style=color:#f92672>in</span> enumerate(verse_docs):
    <span style=color:#66d9ef>for</span> token <span style=color:#f92672>in</span> doc:
        <span style=color:#66d9ef>if</span> token_is_subject_with_action(token):
            span <span style=color:#f92672>=</span> doc[token<span style=color:#f92672>.</span>head<span style=color:#f92672>.</span>left_edge<span style=color:#f92672>.</span>i:token<span style=color:#f92672>.</span>head<span style=color:#f92672>.</span>right_edge<span style=color:#f92672>.</span>i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>]
            data <span style=color:#f92672>=</span> dict(name<span style=color:#f92672>=</span>token<span style=color:#f92672>.</span>orth_,
                        span<span style=color:#f92672>=</span>span<span style=color:#f92672>.</span>text,
                        verb<span style=color:#f92672>=</span>token<span style=color:#f92672>.</span>head<span style=color:#f92672>.</span>lower_,
                        log_prob<span style=color:#f92672>=</span>token<span style=color:#f92672>.</span>head<span style=color:#f92672>.</span>prob,
                        verse<span style=color:#f92672>=</span>verse)
            actors_and_actions<span style=color:#f92672>.</span>append(data)

print(len(actors_and_actions))
</code></pre></div><pre><code>5878
</code></pre>
<h2 id=analysis>Analysis<a hidden class=anchor aria-hidden=true href=#analysis>#</a></h2>
<p>We&rsquo;ve got a list of all the actors and their actions that we&rsquo;ve extracted. For a quick analysis, let&rsquo;s do two things:</p>
<ol>
<li>Figure out the most common action (verb) for each person.</li>
<li>Figure out the most <em>unique</em> action for each person. We&rsquo;ll determine this as the verb that has the lowest probability of appearing in English text.</li>
</ol>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd

action_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(actors_and_actions)

print(<span style=color:#e6db74>&#39;Unique Names:&#39;</span>, action_df[<span style=color:#e6db74>&#39;name&#39;</span>]<span style=color:#f92672>.</span>nunique())

most_common <span style=color:#f92672>=</span> (action_df
    <span style=color:#f92672>.</span>groupby([<span style=color:#e6db74>&#39;name&#39;</span>, <span style=color:#e6db74>&#39;verb&#39;</span>])
    <span style=color:#f92672>.</span>size()
    <span style=color:#f92672>.</span>groupby(level<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, group_keys<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
    <span style=color:#f92672>.</span>nlargest(<span style=color:#ae81ff>1</span>)
    <span style=color:#f92672>.</span>rename(<span style=color:#e6db74>&#39;Count&#39;</span>)
    <span style=color:#f92672>.</span>reset_index(level<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
    <span style=color:#f92672>.</span>rename(columns<span style=color:#f92672>=</span>{
        <span style=color:#e6db74>&#39;verb&#39;</span>: <span style=color:#e6db74>&#39;Most Common&#39;</span>
    })
)

<span style=color:#75715e># exclude log prob &lt; -20, those indicate absence in the model vocabulary</span>
most_unique <span style=color:#f92672>=</span> (action_df[action_df[<span style=color:#e6db74>&#39;log_prob&#39;</span>] <span style=color:#f92672>&gt;</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>20</span>]
    <span style=color:#f92672>.</span>groupby([<span style=color:#e6db74>&#39;name&#39;</span>, <span style=color:#e6db74>&#39;verb&#39;</span>])[<span style=color:#e6db74>&#39;log_prob&#39;</span>]
    <span style=color:#f92672>.</span>min()
    <span style=color:#f92672>.</span>groupby(level<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, group_keys<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
    <span style=color:#f92672>.</span>nsmallest(<span style=color:#ae81ff>1</span>)
    <span style=color:#f92672>.</span>rename(<span style=color:#e6db74>&#39;Log Prob.&#39;</span>)
    <span style=color:#f92672>.</span>reset_index(level <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>)
    <span style=color:#f92672>.</span>rename(columns<span style=color:#f92672>=</span>{
        <span style=color:#e6db74>&#39;verb&#39;</span>: <span style=color:#e6db74>&#39;Most Unique&#39;</span>
    })
)

<span style=color:#75715e># SO groupby credit</span>
<span style=color:#75715e># https: //stackoverflow.com/questions/27842613/pandas-groupby-sort-within-groups</span>
</code></pre></div><pre><code>Unique Names: 534
</code></pre>
<p>Let&rsquo;s take a look at the top 15 actors by verb counts and their most common verb.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>most_common<span style=color:#f92672>.</span>sort_values(<span style=color:#e6db74>&#39;Count&#39;</span>, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)<span style=color:#f92672>.</span>head(<span style=color:#ae81ff>15</span>)
</code></pre></div><div>
<style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}<pre><code>.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</code></pre><p></style></p>
<table border=1 class=dataframe>
<thead>
<tr style=text-align:right>
<th></th>
<th>Most Common</th>
<th>Count</th>
</tr>
<tr>
<th>name</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<th>LORD</th>
<td>said</td>
<td>197</td>
</tr>
<tr>
<th>Jesus</th>
<td>said</td>
<td>89</td>
</tr>
<tr>
<th>David</th>
<td>said</td>
<td>88</td>
</tr>
<tr>
<th>Moses</th>
<td>said</td>
<td>62</td>
</tr>
<tr>
<th>Saul</th>
<td>said</td>
<td>42</td>
</tr>
<tr>
<th>Ye</th>
<td>are</td>
<td>34</td>
</tr>
<tr>
<th>Samuel</th>
<td>said</td>
<td>28</td>
</tr>
<tr>
<th>Blessed</th>
<td>be</td>
<td>24</td>
</tr>
<tr>
<th>God</th>
<td>said</td>
<td>23</td>
</tr>
<tr>
<th>Solomon</th>
<td>made</td>
<td>20</td>
</tr>
<tr>
<th>Joshua</th>
<td>said</td>
<td>18</td>
</tr>
<tr>
<th>Peter</th>
<td>said</td>
<td>18</td>
</tr>
<tr>
<th>Jacob</th>
<td>said</td>
<td>17</td>
</tr>
<tr>
<th>Joseph</th>
<td>said</td>
<td>17</td>
</tr>
<tr>
<th>Pharaoh</th>
<td>said</td>
<td>16</td>
</tr>
</tbody>
</table>
</div>
<p>Looks like a lot of people said things in the Bible, with the exception of Solomon who made a lot of things.</p>
<p>And what were the most unique verbs, as measured by their probability of occurence?
(We&rsquo;ll drop duplicates here so each word is unique)</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>(most_unique
 <span style=color:#f92672>.</span>drop_duplicates(<span style=color:#e6db74>&#39;Most Unique&#39;</span>)
 <span style=color:#f92672>.</span>sort_values(<span style=color:#e6db74>&#39;Log Prob.&#39;</span>, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
 <span style=color:#f92672>.</span>head(<span style=color:#ae81ff>15</span>)
)
</code></pre></div><div>
<style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}<pre><code>.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</code></pre><p></style></p>
<table border=1 class=dataframe>
<thead>
<tr style=text-align:right>
<th></th>
<th>Most Unique</th>
<th>Log Prob.</th>
</tr>
<tr>
<th>name</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<th>Abraham</th>
<td>sojourned</td>
<td>-19.502029</td>
</tr>
<tr>
<th>John</th>
<td>forbad</td>
<td>-19.497028</td>
</tr>
<tr>
<th>Saul</th>
<td>compassed</td>
<td>-19.282370</td>
</tr>
<tr>
<th>David</th>
<td>tarried</td>
<td>-19.168381</td>
</tr>
<tr>
<th>Whosoever</th>
<td>smiteth</td>
<td>-19.147064</td>
</tr>
<tr>
<th>Haman</th>
<td>standeth</td>
<td>-19.006294</td>
</tr>
<tr>
<th>Jehoahaz</th>
<td>besought</td>
<td>-18.932726</td>
</tr>
<tr>
<th>Benjamin</th>
<td>ravin</td>
<td>-18.910282</td>
</tr>
<tr>
<th>Jeroboam</th>
<td>drave</td>
<td>-18.904749</td>
</tr>
<tr>
<th>Julius</th>
<td>entreated</td>
<td>-18.723562</td>
</tr>
<tr>
<th>Joshua</th>
<td>discomfited</td>
<td>-18.674166</td>
</tr>
<tr>
<th>Philip</th>
<td>findeth</td>
<td>-18.523926</td>
</tr>
<tr>
<th>Judas</th>
<td>surnamed</td>
<td>-18.512678</td>
</tr>
<tr>
<th>Abram</th>
<td>hearkened</td>
<td>-18.380188</td>
</tr>
<tr>
<th>Samuel</th>
<td>hewed</td>
<td>-18.333925</td>
</tr>
</tbody>
</table>
</div>
<p>Looks like we&rsquo;ve got some interesting new words to learn! My favorites are <a href=https://www.merriam-webster.com/dictionary/discomfited>discomfited</a> and <a href=https://www.merriam-webster.com/dictionary/ravin>ravin</a>.</p>
<h3 id=visualization>Visualization<a hidden class=anchor aria-hidden=true href=#visualization>#</a></h3>
<p>Let&rsquo;s visualize our results next. We&rsquo;re going to take the top 50 names with the most actions and plot which verse those actions occur in the whole text. We&rsquo;ll also draw vertical lines where each book of the Bible starts. The names will be sorted in order of first appearance.</p>
<p>This should give us an idea at which point in the Bible each of these characters were the most active.</p>
<p>We&rsquo;ll add in some separators to separate different sections of the Bible. Not being a Biblical scholar myself, I used the divisions from <a href=https://www.thoughtco.com/how-the-books-of-the-bible-are-organized-363393>here</a>, which are as follows:</p>
<p><strong>Old Testament:</strong></p>
<ul>
<li><strong>The Pentateuch, or the Books of the Law:</strong> Genesis, Exodus, Leviticus, Numbers, and Deuteronomy.</li>
<li><strong>Old Testament Historical Books:</strong> Joshua, Judges, Ruth, 1 Samuel, 2 Samuel, 1 Kings, 2 Kings, 1 Chronicles, 2 Chronicles, Ezra, Nehemiah, and Esther.</li>
<li><strong>Wisdom Literature:</strong> Job, Psalms, Proverbs, Ecclesiastes, and Song of Solomon.</li>
<li><strong>The Prophets:</strong> Isaiah, Jeremiah, Lamentations, Ezekiel, Daniel, Hosea, Joel, Amos, Obadiah, Jonah, Micah, Nahum, Habakkuk, Zephaniah, Haggai, Zechariah, and Malachi.</li>
</ul>
<p><strong>New Testament:</strong></p>
<ul>
<li><strong>The Gospels:</strong> Matthew, Mark, Luke, and John.</li>
<li><strong>New Testament Historical Books:</strong> Acts</li>
<li><strong>Epistles:</strong> Romans, 1 Corinthians, 2 Corinthians, Galatians, Ephesians, Philippians, Colossians, 1 Thessalonians, 2 Thessalonians, 1 Timothy, 2 Timothy, Titus, Philemon, Hebrews, James, 1 Peter, 2 Peter, 1 John, 2 John, 3 John, and Jude.</li>
<li><strong>Prophecy / Apocalyptic Literature:</strong> Revelation</li>
</ul>
<p>In addition, we&rsquo;ll separate the Old Testament from the New Testament with a red indicator line.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
<span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
<span style=color:#f92672>%</span>matplotlib inline
sns<span style=color:#f92672>.</span>set(context<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;notebook&#39;</span>, style<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;dark&#39;</span>)

most_frequent_actors <span style=color:#f92672>=</span> list(action_df[<span style=color:#e6db74>&#39;name&#39;</span>]<span style=color:#f92672>.</span>value_counts()<span style=color:#f92672>.</span>index[:<span style=color:#ae81ff>50</span>])
top_actors_df <span style=color:#f92672>=</span> action_df[action_df[<span style=color:#e6db74>&#39;name&#39;</span>]<span style=color:#f92672>.</span>isin(most_frequent_actors)]<span style=color:#f92672>.</span>copy()
book_locations <span style=color:#f92672>=</span> (pd<span style=color:#f92672>.</span>DataFrame(bible_json)
                  <span style=color:#f92672>.</span>reset_index()
                  <span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#39;book_id&#39;</span>)[<span style=color:#e6db74>&#39;index&#39;</span>]
                  <span style=color:#f92672>.</span>min()
                  <span style=color:#f92672>.</span>to_dict()
                 )

fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>,<span style=color:#ae81ff>12</span>), dpi<span style=color:#f92672>=</span><span style=color:#ae81ff>144</span><span style=color:#f92672>*</span><span style=color:#ae81ff>2</span>)
sns<span style=color:#f92672>.</span>stripplot(x<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;verse&#39;</span>, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;name&#39;</span>, 
              data<span style=color:#f92672>=</span>top_actors_df, ax<span style=color:#f92672>=</span>ax,
              color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;xkcd:cerulean&#39;</span>,
              size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.25</span>, jitter<span style=color:#f92672>=</span><span style=color:#ae81ff>0.25</span>)

sns<span style=color:#f92672>.</span>despine(bottom<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, left<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)

<span style=color:#66d9ef>for</span> book, verse_num <span style=color:#f92672>in</span> book_locations<span style=color:#f92672>.</span>items():
    ax<span style=color:#f92672>.</span>axvline(verse_num, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, lw<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;w&#39;</span>)

divisions <span style=color:#f92672>=</span> [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>18</span>, <span style=color:#ae81ff>23</span>, <span style=color:#ae81ff>40</span>, <span style=color:#ae81ff>44</span>, <span style=color:#ae81ff>45</span>, <span style=color:#ae81ff>65</span>]
<span style=color:#66d9ef>for</span> div <span style=color:#f92672>in</span> divisions:
    ax<span style=color:#f92672>.</span>axvline(book_locations[div], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, lw<span style=color:#f92672>=</span><span style=color:#ae81ff>1.5</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;grey&#39;</span>)

ax<span style=color:#f92672>.</span>axvline(book_locations[<span style=color:#ae81ff>40</span>], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, lw<span style=color:#f92672>=</span><span style=color:#ae81ff>1.75</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;xkcd:coral&#39;</span>)

ax<span style=color:#f92672>.</span>set_xlim(left<span style=color:#f92672>=-</span><span style=color:#ae81ff>150</span>)

ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#34;Where Actions Occur in the Bible</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>Characters Sorted by First Appearance&#34;</span>);
</code></pre></div><p><img loading=lazy src=/images/bible-character-locations.png alt=png>
</p>
<h2 id=visual-analysis>Visual Analysis<a hidden class=anchor aria-hidden=true href=#visual-analysis>#</a></h2>
<ul>
<li>God is densely referred to at the beginning of the Bible, in Genesis.</li>
<li>LORD stops being used as an entity in books of the New Testament.</li>
<li>We can see the first time Paul is referred to in the middle of Acts. (first book after the gospels)</li>
<li>There&rsquo;s not a lot of mention of entities in the <em>Wisdom & Poetry</em> Sections of the Bible.</li>
<li>Jesus' life is densely chronicled throughout the gospels.</li>
<li>Pilate appears at the end of each of the gospels.</li>
</ul>
<h2 id=issues-with-this-approach>Issues with this Approach<a hidden class=anchor aria-hidden=true href=#issues-with-this-approach>#</a></h2>
<ul>
<li>Entity Recognition can&rsquo;t tell the difference between two different people with the same name.
<ul>
<li>King Saul (Old Testament)</li>
<li>Paul (The Apostle) is referred to as Saul until midway through the book of Acts</li>
</ul>
</li>
<li>Some nouns are not actual entities. (Ye)</li>
<li>Some nouns could use more context with full names. (Pilate)</li>
</ul>
<h2 id=next-steps>Next Steps<a hidden class=anchor aria-hidden=true href=#next-steps>#</a></h2>
<p>As always, there are ways to extend and improve this analysis. Here&rsquo;s a few I&rsquo;ve thought of while writing this:</p>
<ol>
<li>Find relationships between entities using dependency relations and understand the characters through a network analysis approach.</li>
<li>Improve the entity extraction to capture entities beyond single names</li>
<li>Do an analysis of non-person entities and their linguistic relations - which locations are mentioned throughout the Bible?</li>
</ol>
<h2 id=wrap-up>Wrap Up<a hidden class=anchor aria-hidden=true href=#wrap-up>#</a></h2>
<p>We can get pretty far doing some interesting analysis by only using token-level attributes from text! In this blog post, we covered three key NLP tools:</p>
<ol>
<li><strong>Part of Speech Tagging</strong> - What type of word is this?</li>
<li><strong>Dependency Parsing</strong> - How is this word related to other words in this sentence?</li>
<li><strong>Named Entity Recognition</strong> - Is this word a proper noun?</li>
</ol>
<p>We applied these three tools together to discover who the major actors are in the Bible and what actions they take. We plotted those actors and actions to understand where each actor had their major actions.</p>
<h3 id=thanks>Thanks<a hidden class=anchor aria-hidden=true href=#thanks>#</a></h3>
<p>Thanks to <a href=http://www.vickiboykis.com/>Vicki Boykis</a> and <a href=http://austinrochford.com/>Austin Rochford</a> for providing feedback on earlier versions of this post.</p>
</div>
<footer class=post-footer>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://www.peterbaumgartner.com/>Peter Baumgartner</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>